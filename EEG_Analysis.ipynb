{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "from mne.stats import permutation_cluster_test\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as ss\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from copy import deepcopy as copy\n",
    "plt.style.use(\"paper_style.mplstyle\")\n",
    "import matplotlib\n",
    "matplotlib.rcParams['font.sans-serif'] = \"Arial\"\n",
    "matplotlib.rcParams['font.family'] = \"sans-serif\"\n",
    "import pingouin as pg\n",
    "from cBCI.groups.performance import majority, statistics\n",
    "from cBCI.plotting.accuracy import group_accuracy\n",
    "\n",
    "DATA_FOLDER = \"../data/EEG/\"\n",
    "TRIALS_PER_SESSION = 30\n",
    "RESULT_FOLDER = \"../results/\"\n",
    "GROUP_RESULT_FOLDER = RESULT_FOLDER\n",
    "MAX_SESSIONS = 6\n",
    "NUM_TR_TO_SKIP = 2\n",
    "TR_PER_RUN = 235\n",
    "SUBJECTS = [102, 103, 104, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116]\n",
    "event_id = {'TR': 1,\n",
    "            'SessionStart': 2,\n",
    "            'TrialStart': 3,\n",
    "            'Decision': 4,\n",
    "            'Confidence': 5,\n",
    "            'FinalDecision': 6,\n",
    "            'StimulusScreen': 7,\n",
    "            'DecisionScreen': 8, \n",
    "            'ConfidenceScreen': 9,\n",
    "            'FeedbackScreen': 10,\n",
    "            'FinalDecisionScreen': 11,\n",
    "            'TrialEnd': 12}\n",
    "os.makedirs(RESULT_FOLDER, exist_ok=True)\n",
    "os.makedirs(GROUP_RESULT_FOLDER, exist_ok=True)\n",
    "INCORRECT_COLOR = \"#ff0000\"\n",
    "CORRECT_COLOR = \"#147ffa\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess EEG data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for SUBJECT in SUBJECTS:\n",
    "    # Load EEG data corrected from MRI artifacts\n",
    "    filename = glob.glob(\"%s%d*obs2.mff\" % (DATA_FOLDER, SUBJECT))[0]\n",
    "    print(\"Load\", filename)\n",
    "    raw = mne.io.read_raw_egi(filename, preload=True, exclude=[])\n",
    "    # Set the montage\n",
    "    renamed = {}\n",
    "    for channel in raw.ch_names:\n",
    "        renamed[channel] = \"Cz\" if channel == \"E129\" else channel\n",
    "    raw.rename_channels(renamed)\n",
    "    raw.set_montage(mne.channels.make_standard_montage(\"GSN-HydroCel-129\"))\n",
    "    # Remove any EEG reference\n",
    "    raw, _ = mne.set_eeg_reference(raw, [])\n",
    "    # Band-pass filter between 1 and 40 Hz\n",
    "    raw.filter(1, 40, fir_design='firwin', n_jobs=8)\n",
    "    # Extract events\n",
    "    events = mne.find_events(raw, shortest_event=1)\n",
    "    mne.write_events(\"%ss%d/%d_eve.fif\" % (RESULT_FOLDER, SUBJECT, SUBJECT), events)\n",
    "    # Order events by timestamp\n",
    "    events = events[events[:, 0].argsort()]\n",
    "    print(\"Number of TRs:\", len(events[events[:, -1] == event_id['TR']]))\n",
    "    # Extract epochs and subsample them\n",
    "    for event, baseline, ranges in zip([\"TrialStart\", \"StimulusScreen\", \"Decision\", \"FeedbackScreen\"], \n",
    "                                       [None, (-0.6, -0.5), (-0.1, 0.0), (-0.1, 0.0)],\n",
    "                                       [(-0.5, 0), (-0.6, 1.5), (-0.1, 2.0), (-0.1, 2.0)]):\n",
    "        print(\"Extracting %s epochs\" % event)\n",
    "        # All epochs except for TrialStart are 2.1 seconds long, include a 100 ms baseline and are subsampled to 100 Hz\n",
    "        epochs = mne.Epochs(raw, events=events, event_id=event_id[event],\n",
    "                            tmin=ranges[0], tmax=ranges[1], baseline=baseline, \n",
    "                            preload=True, verbose=False)\n",
    "        epochs.resample(100., npad='auto')\n",
    "        all_epochs_trials = epochs.selection\n",
    "        # Epochs with EEG signal bigger than 5 mV are rejected\n",
    "        reject = dict(eeg=5e-3)\n",
    "        epochs.drop_bad(reject=reject, verbose=False)\n",
    "        is_rejected = np.array([False if i in epochs.selection else True for i in all_epochs_trials])\n",
    "        np.save(\"%ss%d/s%d_is_rejected_%s.npy\" % (RESULT_FOLDER, SUBJECT, SUBJECT, event.split(\"Screen\")[0].lower()), is_rejected)\n",
    "        print(\"Rejected %d epochs\" % np.sum(is_rejected))\n",
    "        epochs.save(\"%ss%d/s%d_%s-epo.fif\" % (RESULT_FOLDER, SUBJECT, SUBJECT, event.split(\"Screen\")[0].lower()), overwrite=True)\n",
    "    if not os.path.isfile(\"%s../MRI/s%d/s%d_stim_file.1D\" % (DATA_FOLDER, SUBJECT, SUBJECT)):\n",
    "        # Create stimulus files for fMRI analysis\n",
    "        trial_index = 0\n",
    "        valid_events = events[events[:, 2] < 13]\n",
    "        tr_correct = []\n",
    "        tr_incorrect = []\n",
    "        tr_confident = []\n",
    "        tr_notconfident = []\n",
    "        tr_trust = []\n",
    "        tr_distrust = []\n",
    "        delay_between_trs = np.diff(events[events[:, 2] == event_id[\"TR\"]][:, 0])\n",
    "        for i in range(len(valid_events)):\n",
    "            if valid_events[i, 2] == event_id[\"TR\"]:\n",
    "                # If the TR demarks the stimulus\n",
    "                if i < (len(valid_events)-2) and (valid_events[i+1, 2] == event_id[\"StimulusScreen\"] or\n",
    "                                                 (valid_events[i+1, 2] != event_id[\"TR\"] and \n",
    "                                                  valid_events[i+2, 2] == event_id[\"StimulusScreen\"]) or\n",
    "                                                 (valid_events[i+1, 2] != event_id[\"TR\"] and \n",
    "                                                  valid_events[i+2, 2] != event_id[\"TR\"] and \n",
    "                                                  valid_events[i+3, 2] == event_id[\"StimulusScreen\"])):\n",
    "                    # Trial begins\n",
    "                    session_index = trial_index // TRIALS_PER_SESSION\n",
    "                    trial_index += 1\n",
    "                    # Get correctness from txt file\n",
    "                    data_file = glob.glob(\"%smaps_protocol_mri_with_*-%d-1.txt\" % (DATA_FOLDER, SUBJECT))[0]\n",
    "                    try:\n",
    "                        txt_file = np.loadtxt(data_file, dtype=str, delimiter=\"\\n\", encoding='utf-16')\n",
    "                    except:\n",
    "                        txt_file = np.loadtxt(data_file, dtype=str, delimiter=\"\\n\", encoding='utf-8')\n",
    "                    current_trial = False\n",
    "                    decision = 0\n",
    "                    confidence = 0\n",
    "                    agent_decision = 0\n",
    "                    agent_confidence = 0\n",
    "                    final_decision = 0\n",
    "                    correct_answer = 0\n",
    "                    for row in txt_file:\n",
    "                        if \"PreImageFile\" in row and (SUBJECT == 101 or (\"stim_%d\" % (session_index+1)) in row) and (\"%03d\" % (trial_index - session_index*TRIALS_PER_SESSION)) in row:\n",
    "                            current_trial = True\n",
    "                        if \"CorrectAnswer:\" in row:\n",
    "                            correct_answer = int(row.split(\": \")[1])\n",
    "                        if \"Confidence\" in row and \"RESP\" in row:\n",
    "                            if len(row.split(\": \")) < 2 or row.split(\": \")[1] == '':\n",
    "                                confidence = -1\n",
    "                            else:\n",
    "                                confidence = int(row.split(\": \")[1])\n",
    "                        if \"Agent\" in row and \"Decision\" in row:\n",
    "                            if len(row.split(\": \")) < 2 or row.split(\": \")[1] == '?':\n",
    "                                agent_decision = -1\n",
    "                            else:\n",
    "                                agent_decision = int(row.split(\": \")[1])\n",
    "                        if \"Agent\" in row and \"Confidence\" in row:\n",
    "                            if len(row.split(\": \")) < 2 or row.split(\": \")[1] == '?':\n",
    "                                agent_confidence = -1\n",
    "                            else:\n",
    "                                agent_confidence = int(row.split(\": \")[1])\n",
    "                        if \"Decision\" in row and \"RESP\" in row and \"Final\" in row and current_trial and correct_answer != 0:\n",
    "                            if len(row.split(\": \")) < 2 or row.split(\": \")[1] == '':\n",
    "                                final_decision = -1\n",
    "                            else:\n",
    "                                final_decision = int(row.split(\": \")[1])\n",
    "                            current_trial = False\n",
    "                            break\n",
    "                        if \"Decision\" in row and \"RESP\" in row and \"Final\" not in row and correct_answer != 0:\n",
    "                            if len(row.split(\": \")) < 2 or row.split(\": \")[1] == '':\n",
    "                                decision = -1\n",
    "                            else:\n",
    "                                decision = int(row.split(\": \")[1])\n",
    "                    tr_trust.append(0)\n",
    "                    tr_distrust.append(0)\n",
    "                    if current_trial == True:\n",
    "                        # This is a non-valid trial as the decision has not been found, so mark it as neither correct nor incorrect\n",
    "                        tr_correct.append(0)\n",
    "                        tr_incorrect.append(0)\n",
    "                    else:\n",
    "                        if decision == correct_answer:\n",
    "                            tr_correct.append(1)\n",
    "                            tr_incorrect.append(0)\n",
    "                        else:\n",
    "                            tr_correct.append(0)\n",
    "                            tr_incorrect.append(1)\n",
    "                    if confidence == 3 or confidence == 4:\n",
    "                        tr_confident.append(1)\n",
    "                        tr_notconfident.append(0)\n",
    "                    elif confidence == 1 or confidence == 2:\n",
    "                        tr_confident.append(0)\n",
    "                        tr_notconfident.append(1)\n",
    "                    else:\n",
    "                        # Confident was not reported, so exclude this trial\n",
    "                        tr_confident.append(0)\n",
    "                        tr_notconfident.append(0)\n",
    "                # If it is the TR right before the feedback screen...\n",
    "                elif i < len(valid_events)-2 and valid_events[i+1, 2] == event_id[\"FeedbackScreen\"]:\n",
    "                    tr_correct.append(0)\n",
    "                    tr_incorrect.append(0)\n",
    "                    tr_confident.append(0)\n",
    "                    tr_notconfident.append(0)\n",
    "                    if current_trial == True:\n",
    "                        # This is a non-valid trial as the decision has not been found, so mark it as neither trust nor distrust\n",
    "                        tr_trust.append(0)\n",
    "                        tr_distrust.append(0)\n",
    "                    else:\n",
    "                        if (decision == agent_decision and decision == final_decision) or (decision != agent_decision and final_decision == agent_decision):\n",
    "                            tr_trust.append(1)\n",
    "                            tr_distrust.append(0)\n",
    "                        elif (decision == agent_decision and decision != final_decision) or (decision != agent_decision and final_decision == decision):\n",
    "                            tr_trust.append(0)\n",
    "                            tr_distrust.append(1)\n",
    "                        else:\n",
    "                            tr_trust.append(0)\n",
    "                            tr_distrust.append(0)\n",
    "                else:\n",
    "                    tr_correct.append(0)\n",
    "                    tr_incorrect.append(0)\n",
    "                    tr_confident.append(0)\n",
    "                    tr_notconfident.append(0)\n",
    "                    tr_trust.append(0)\n",
    "                    tr_distrust.append(0)\n",
    "        num_runs = int(round(trial_index / TRIALS_PER_SESSION, 0))\n",
    "        print(\"num runs\", num_runs)\n",
    "        if len(tr_correct) > TR_PER_RUN*num_runs:\n",
    "            # Remove initial TRs that are not sent to the scanner\n",
    "            print(\"Fixing TRs\")\n",
    "            tr_correct = tr_correct[len(tr_correct)-TR_PER_RUN*num_runs:]\n",
    "            tr_incorrect = tr_incorrect[len(tr_incorrect)-TR_PER_RUN*num_runs:]\n",
    "            tr_confident = tr_confident[len(tr_confident)-TR_PER_RUN*num_runs:]\n",
    "            tr_notconfident = tr_notconfident[len(tr_notconfident)-TR_PER_RUN*num_runs:]\n",
    "            tr_trust = tr_trust[len(tr_trust)-TR_PER_RUN*num_runs:]\n",
    "            tr_distrust = tr_distrust[len(tr_distrust)-TR_PER_RUN*num_runs:]\n",
    "        if len(tr_correct) < TR_PER_RUN*num_runs:\n",
    "            for i in range(TR_PER_RUN*num_runs-len(tr_correct)):\n",
    "                tr_correct.append(0)\n",
    "                tr_incorrect.append(0)\n",
    "                tr_confident.append(0)\n",
    "                tr_notconfident.append(0)\n",
    "                tr_trust.append(0)\n",
    "                tr_distrust.append(0)\n",
    "        assert len(tr_correct) // num_runs == TR_PER_RUN\n",
    "        tr_index_to_remove = []\n",
    "        # Skip first NUM_TR_TO_SKIP in each run\n",
    "        for run in range(num_runs):\n",
    "            tr_index_to_remove += list(range(run*TR_PER_RUN, run*TR_PER_RUN+NUM_TR_TO_SKIP))\n",
    "        for tr in sorted(tr_index_to_remove, reverse=True):\n",
    "            del tr_correct[tr]\n",
    "            del tr_incorrect[tr]\n",
    "            del tr_confident[tr]\n",
    "            del tr_notconfident[tr]\n",
    "            del tr_trust[tr]\n",
    "            del tr_distrust[tr]\n",
    "        print(\"TOTAL VALID TRIALS\", trial_index-num_runs*(NUM_TR_TO_SKIP != 0))\n",
    "        print(len(tr_correct), len(tr_incorrect), len(tr_confident), len(tr_notconfident), len(tr_trust), len(tr_distrust))\n",
    "        tr_file = np.vstack((tr_correct, tr_incorrect))\n",
    "        os.makedirs(\"%s../MRI/s%d/\" % (DATA_FOLDER, SUBJECT), exist_ok=True)\n",
    "        np.savetxt(\"%s../MRI/s%d/s%d_stim_file.1D\" % (DATA_FOLDER, SUBJECT, SUBJECT), tr_file.T, fmt=\"%d\")\n",
    "        np.savetxt(\"%s../MRI/s%d/s%d_correct_stim_file.1D\" % (DATA_FOLDER, SUBJECT, SUBJECT), tr_file.T[:, 0], fmt=\"%d\")\n",
    "        np.savetxt(\"%s../MRI/s%d/s%d_incorrect_stim_file.1D\" % (DATA_FOLDER, SUBJECT, SUBJECT), tr_file.T[:, 1], fmt=\"%d\")\n",
    "        tr_file = np.vstack((tr_trust, tr_distrust))\n",
    "        np.savetxt(\"%s../MRI/s%d/s%d_stim_file_trust.1D\" % (DATA_FOLDER, SUBJECT, SUBJECT), tr_file.T, fmt=\"%d\")\n",
    "        np.savetxt(\"%s../MRI/s%d/s%d_trust_stim_file.1D\" % (DATA_FOLDER, SUBJECT, SUBJECT), tr_file.T[:, 0], fmt=\"%d\")\n",
    "        np.savetxt(\"%s../MRI/s%d/s%d_distrust_stim_file.1D\" % (DATA_FOLDER, SUBJECT, SUBJECT), tr_file.T[:, 1], fmt=\"%d\")\n",
    "        tr_file = np.vstack((tr_confident, tr_notconfident))\n",
    "        np.savetxt(\"%s../MRI/s%d/s%d_stim_file_confidence.1D\" % (DATA_FOLDER, SUBJECT, SUBJECT), tr_file.T, fmt=\"%d\")\n",
    "        np.savetxt(\"%s../MRI/s%d/s%d_confident_stim_file.1D\" % (DATA_FOLDER, SUBJECT, SUBJECT), tr_file.T[:, 0], fmt=\"%d\")\n",
    "        np.savetxt(\"%s../MRI/s%d/s%d_notconfident_stim_file.1D\" % (DATA_FOLDER, SUBJECT, SUBJECT), tr_file.T[:, 1], fmt=\"%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BCI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decode confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NUM_FEATURES = 16\n",
    "NUM_FOLDS = 10\n",
    "behavioral_data = pd.read_csv(\"%s../BEHAVIOR/behavioral_data.csv\" % GROUP_RESULT_FOLDER)\n",
    "bci_confidence_stimulus = np.ones((len(SUBJECTS), MAX_SESSIONS*TRIALS_PER_SESSION))\n",
    "bci_confidence_stimulus_predict = np.ones((len(SUBJECTS), MAX_SESSIONS*TRIALS_PER_SESSION))\n",
    "bci_confidence_feedback = np.ones((len(SUBJECTS), MAX_SESSIONS*TRIALS_PER_SESSION))\n",
    "bci_confidence_feedback_predict = np.ones((len(SUBJECTS), MAX_SESSIONS*TRIALS_PER_SESSION))\n",
    "kf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=0)\n",
    "confidence = np.ones((len(SUBJECTS), MAX_SESSIONS*TRIALS_PER_SESSION))\n",
    "is_correct = np.zeros((len(SUBJECTS), MAX_SESSIONS*TRIALS_PER_SESSION), dtype=bool)\n",
    "is_correct_final = np.zeros((len(SUBJECTS), MAX_SESSIONS*TRIALS_PER_SESSION), dtype=bool)\n",
    "for train_index, test_index in kf.split(range(MAX_SESSIONS*TRIALS_PER_SESSION)):\n",
    "    IS_TRAIN = np.zeros((MAX_SESSIONS*TRIALS_PER_SESSION), dtype=bool)\n",
    "    IS_TRAIN[train_index] = 1\n",
    "    for s, subject in enumerate(SUBJECTS):\n",
    "        decisions = behavioral_data[\"Decisions_%s\" % subject].values\n",
    "        final_decisions = behavioral_data[\"Final_Decisions_%s\" % subject].values\n",
    "        # STIMULUS LOCKED\n",
    "        epochs = mne.read_epochs(\"%ss%d/s%d_stimulus-epo.fif\" % (RESULT_FOLDER, subject, subject), \n",
    "                                 preload=True, verbose=False)\n",
    "        is_rejected = np.load(\"%ss%d/s%d_is_rejected_stimulus.npy\" % (RESULT_FOLDER, subject, subject))\n",
    "        if len(is_rejected) < MAX_SESSIONS*TRIALS_PER_SESSION:\n",
    "            is_rejected = np.hstack((is_rejected, [True]))\n",
    "        # Bad epochs\n",
    "        bci_confidence_stimulus[s, np.where(is_rejected)] = np.nan\n",
    "        # Missing responses\n",
    "        bci_confidence_stimulus[s, np.where(decisions == -1)] = -1\n",
    "        epochs_to_drop = np.where(decisions[~is_rejected] == -1)[0]\n",
    "        bci_confidence_stimulus[s, np.where(decisions == -1)] = np.nan\n",
    "        epochs.drop(epochs_to_drop)\n",
    "        # This handles incomplete epochs at the end\n",
    "        if len(epochs) < np.sum(~np.isnan(bci_confidence_stimulus[s])):\n",
    "            bci_confidence_stimulus[s, -1] = np.nan\n",
    "        # Behavioral data\n",
    "        confidence[s] = behavioral_data[\"Confidence_%s\" % subject].values\n",
    "        is_correct[s] = (decisions == behavioral_data[\"Correct_Answer\"]).values\n",
    "        # Prepare epochs\n",
    "        epoch_data = epochs.pick(\"eeg\").drop_channels([\"Cz\"]).get_data()\n",
    "        events = epochs.events\n",
    "        events[is_correct[s, ~np.isnan(bci_confidence_stimulus[s])], -1] = 1\n",
    "        events[~is_correct[s, ~np.isnan(bci_confidence_stimulus[s])], -1] = 2\n",
    "        event_id = dict(correct=1, incorrect=2)\n",
    "        raw_epochs = mne.EpochsArray(data=epoch_data, info=epochs.info, events=events, event_id=event_id)\n",
    "        # Classification pipeline\n",
    "        y_train = is_correct[s, ~np.isnan(bci_confidence_stimulus[s])][IS_TRAIN[~np.isnan(bci_confidence_stimulus[s])]]\n",
    "        y_test = is_correct[s, ~np.isnan(bci_confidence_stimulus[s])][~IS_TRAIN[~np.isnan(bci_confidence_stimulus[s])]]\n",
    "        featurizer = mne.preprocessing.Xdawn(n_components=NUM_FEATURES)\n",
    "        clf = make_pipeline(featurizer, \n",
    "                            mne.decoding.Vectorizer(),\n",
    "                            svm.SVC(C=1e3, probability=True, gamma='scale', class_weight=\"balanced\", \n",
    "                                    random_state=0))\n",
    "        clf.fit(raw_epochs[IS_TRAIN[~np.isnan(bci_confidence_stimulus[s])]], y_train.astype(int))\n",
    "        \n",
    "        train_idx = np.where(np.logical_and(IS_TRAIN, ~np.isnan(bci_confidence_stimulus[s])))\n",
    "        test_idx = np.where(np.logical_and(~IS_TRAIN, ~np.isnan(bci_confidence_stimulus[s])))\n",
    "        bci_confidence_stimulus[s, test_idx] = clf.predict_proba(raw_epochs[~IS_TRAIN[~np.isnan(bci_confidence_stimulus[s])]].get_data())[:, 1]\n",
    "        bci_confidence_stimulus_predict[s, test_idx] = clf.predict(raw_epochs[~IS_TRAIN[~np.isnan(bci_confidence_stimulus[s])]])\n",
    "        \n",
    "        # FEEDBACK LOCKED\n",
    "        epochs = mne.read_epochs(\"%ss%d/s%d_feedback-epo.fif\" % (RESULT_FOLDER, subject, subject), \n",
    "                                 preload=True, verbose=False)\n",
    "        is_rejected = np.load(\"%ss%d/s%d_is_rejected_feedback.npy\" % (RESULT_FOLDER, subject, subject))\n",
    "        if len(is_rejected) < MAX_SESSIONS*TRIALS_PER_SESSION:\n",
    "            is_rejected = np.hstack((is_rejected, [True]))\n",
    "        # Bad epochs\n",
    "        bci_confidence_feedback[s, np.where(is_rejected)] = np.nan\n",
    "        # Missing responses\n",
    "        bci_confidence_feedback[s, np.where(final_decisions == -1)] = -1\n",
    "        epochs_to_drop = np.where(final_decisions[~is_rejected] == -1)[0]\n",
    "        epochs.drop(epochs_to_drop)\n",
    "        bci_confidence_feedback[s, np.where(final_decisions == -1)] = np.nan\n",
    "        # This handles incomplete epochs at the end\n",
    "        if len(epochs) < np.sum(~np.isnan(bci_confidence_feedback[s])):\n",
    "            bci_confidence_feedback[s, -1] = np.nan\n",
    "        is_correct_final[s] = (final_decisions == behavioral_data[\"Correct_Answer\"]).values\n",
    "        # Prepare epochs\n",
    "        epoch_data = epochs.pick(\"eeg\").drop_channels([\"Cz\"]).get_data()\n",
    "        events = epochs.events\n",
    "        events[is_correct_final[s, ~np.isnan(bci_confidence_feedback[s])], -1] = 1\n",
    "        events[~is_correct_final[s, ~np.isnan(bci_confidence_feedback[s])], -1] = 2\n",
    "        event_id = dict(correct=1, incorrect=2)\n",
    "        raw_epochs = mne.EpochsArray(data=epoch_data, info=epochs.info, events=events, event_id=event_id)\n",
    "        # Classification pipeline\n",
    "        y_train = is_correct_final[s, ~np.isnan(bci_confidence_feedback[s])][IS_TRAIN[~np.isnan(bci_confidence_feedback[s])]]\n",
    "        y_test = is_correct_final[s, ~np.isnan(bci_confidence_feedback[s])][~IS_TRAIN[~np.isnan(bci_confidence_feedback[s])]]\n",
    "        featurizer = mne.preprocessing.Xdawn(n_components=NUM_FEATURES)\n",
    "        clf = make_pipeline(featurizer, \n",
    "                            mne.decoding.Vectorizer(),\n",
    "                            svm.SVC(C=1e3, probability=True, gamma='scale', class_weight=\"balanced\", \n",
    "                                    random_state=0))\n",
    "        clf.fit(raw_epochs[IS_TRAIN[~np.isnan(bci_confidence_feedback[s])]], y_train.astype(int))\n",
    "        train_idx = np.where(np.logical_and(IS_TRAIN, ~np.isnan(bci_confidence_feedback[s])))[0]\n",
    "        test_idx = np.where(np.logical_and(~IS_TRAIN, ~np.isnan(bci_confidence_feedback[s])))[0]\n",
    "        bci_confidence_feedback[s, test_idx] = clf.predict_proba(raw_epochs[~IS_TRAIN[~np.isnan(bci_confidence_feedback[s])]])[:, 1]\n",
    "        bci_confidence_feedback_predict[s, test_idx] = clf.predict(raw_epochs[~IS_TRAIN[~np.isnan(bci_confidence_feedback[s])]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_accuracies = []\n",
    "all_accuracies_final = []\n",
    "for s in range(len(SUBJECTS)):\n",
    "    all_accuracies.append(accuracy_score(is_correct[s], bci_confidence_stimulus_predict[s]))\n",
    "    all_accuracies_final.append(accuracy_score(bci_confidence_feedback_predict[s], is_correct_final[s]))\n",
    "print(all_accuracies)\n",
    "print(np.mean(all_accuracies))\n",
    "print(all_accuracies_final)\n",
    "print(np.mean(all_accuracies_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ss.spearmanr(np.mean(is_correct, axis=1), np.nanmean(bci_confidence_stimulus, axis=1)))\n",
    "print(ss.spearmanr(np.mean(is_correct_final, axis=1), np.nanmean(bci_confidence_feedback, axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving data to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(bci_confidence_stimulus.T, columns=[\"BCIConf_%s\" % s for s in SUBJECTS])\n",
    "df = df.merge(pd.DataFrame(confidence.T, columns=[\"confidence_%s\" % s for s in SUBJECTS]), left_index=True, right_index=True)\n",
    "df = df.merge(pd.DataFrame(is_correct.T, columns=[\"is_correct_%s\" % s for s in SUBJECTS]), left_index=True, right_index=True)\n",
    "df = df.merge(pd.DataFrame(bci_confidence_feedback.T, columns=[\"BCIConf_feedback_%s\" % s for s in SUBJECTS]), left_index=True, right_index=True)\n",
    "df = df.merge(pd.DataFrame(is_correct_final.T, columns=[\"is_correct_final_%s\" % s for s in SUBJECTS]), left_index=True, right_index=True)\n",
    "# df = df.merge(pd.DataFrame(is_train.T, columns=[\"is_train\"]), left_index=True, right_index=True)\n",
    "df.to_csv(GROUP_RESULT_FOLDER+\"bci_confidence.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Showing underconfident bias (Fig. 3B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(GROUP_RESULT_FOLDER+\"bci_confidence.csv\", index_col=0)\n",
    "accuracy = df[df.columns[(df.columns.to_series().str.contains('is_correct')) & (~df.columns.to_series().str.contains('final'))]].to_numpy().T.astype(int)\n",
    "final_accuracy = df[df.columns[df.columns.to_series().str.contains('is_correct_final')]].to_numpy().T.astype(int)\n",
    "bci_confidence = df[df.columns[(df.columns.to_series().str.contains('BCIConf')) & (~df.columns.to_series().str.contains('feedback'))]].to_numpy().T.astype(float)\n",
    "confidence = df[df.columns[(df.columns.to_series().str.contains('confidence')) & (~df.columns.to_series().str.contains('hybrid'))]].to_numpy().T.astype(float)\n",
    "confidence[confidence < 0] = np.nan\n",
    "confidence = (confidence-1)/3\n",
    "df = pd.DataFrame()\n",
    "df[\"Confidence\"] = [\"Reported\"]*len(confidence)*2+[\"BCI\"]*len(bci_confidence)*2\n",
    "df[\"Accuracy\"] = [\"1st decision\"]*len(accuracy)+[\"2nd decision\"]*len(final_accuracy)+[\"1st decision\"]*len(accuracy)+[\"2nd decision\"]*len(final_accuracy)\n",
    "df[\"x\"] = np.hstack((np.nanmean(100*accuracy, axis=1), np.nanmean(100*final_accuracy, axis=1), np.nanmean(100*accuracy, axis=1), np.nanmean(100*final_accuracy, axis=1)))\n",
    "df[\"y\"] = np.hstack((np.nanmean(100*confidence, axis=1), np.nanmean(100*confidence, axis=1), np.nanmean(100*bci_confidence, axis=1), np.nanmean(100*bci_confidence, axis=1)))\n",
    "g = sns.lmplot(x=\"x\", y=\"y\", hue=\"Confidence\", col=\"Accuracy\", facet_kws={\"sharey\": 'row'},\n",
    "               data=df, height=3, palette=dict(Reported=\"#ee9be4\", BCI=\"#4a4bc7\"),\n",
    "               scatter_kws={\"s\": 25}, line_kws={\"lw\": 3}, seed=2, robust=False, n_boot=1000, truncate=False)\n",
    "g.set(xlim=(20, 90), ylim=(20, 90), xlabel=\"\", ylabel=\"\", xticks=[20, 90], \n",
    "      yticks=[20, 90], title=\"\").fig.subplots_adjust(wspace=.15)\n",
    "g.axes[0, 0].plot([0, 100], [0, 100], zorder=-5, color='0.5', ls=\"--\", lw=1)\n",
    "g.axes[0, 1].plot([0, 100], [0, 100], zorder=-5, color='0.5', ls=\"--\", lw=1)\n",
    "g.axes[0, 0].grid(visible=False)\n",
    "g.axes[0, 1].grid(visible=False)\n",
    "print(pg.corr(np.nanmean(100*accuracy, axis=1), np.nanmean(100*confidence, axis=1), method='spearman'))\n",
    "print(pg.compute_effsize(np.nanmean(100*accuracy, axis=1), np.nanmean(100*confidence, axis=1)))\n",
    "print(pg.corr(np.nanmean(100*accuracy, axis=1), np.nanmean(100*bci_confidence, axis=1), method='spearman'))\n",
    "print(pg.compute_effsize(np.nanmean(100*accuracy, axis=1), np.nanmean(100*bci_confidence, axis=1)))\n",
    "print(pg.corr(np.nanmean(100*final_accuracy, axis=1), np.nanmean(100*confidence, axis=1), method='spearman'))\n",
    "print(pg.compute_effsize(np.nanmean(100*final_accuracy, axis=1), np.nanmean(100*confidence, axis=1)))\n",
    "print(pg.corr(np.nanmean(100*final_accuracy, axis=1), np.nanmean(100*bci_confidence, axis=1), method='spearman'))\n",
    "print(pg.compute_effsize(np.nanmean(100*final_accuracy, axis=1), np.nanmean(100*bci_confidence, axis=1)))\n",
    "plt.savefig(\"%saccuracy_confidence_correlations.pdf\" % GROUP_RESULT_FOLDER, dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate group decisions (Fig. 3A)\n",
    "\n",
    "This plot will take a few minutes to generate as all possible groups of all sizes needs to be simulated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_GROUP = None\n",
    "df = pd.read_csv(GROUP_RESULT_FOLDER+\"bci_confidence.csv\", index_col=0)\n",
    "accuracy = df[df.columns[(df.columns.to_series().str.contains('is_correct')) & (~df.columns.to_series().str.contains('final'))]].to_numpy().T.astype(int)\n",
    "final_accuracy = df[df.columns[df.columns.to_series().str.contains('is_correct_final')]].to_numpy().T.astype(int)\n",
    "bci_confidence = df[df.columns[(df.columns.to_series().str.contains('BCIConf')) & (~df.columns.to_series().str.contains('feedback'))]].to_numpy().T.astype(float)\n",
    "hybrid_confidence = df[df.columns[(df.columns.to_series().str.contains('hybrid_confidence')) & (~df.columns.to_series().str.contains('feedback'))]].to_numpy().T.astype(float)\n",
    "attention = df[df.columns[(df.columns.to_series().str.contains('attention')) & (~df.columns.to_series().str.contains('feedback'))]].to_numpy().T.astype(float)\n",
    "bci_confidence_feedback = df[df.columns[df.columns.to_series().str.contains('BCIConf_feedback')]].to_numpy().T.astype(float)\n",
    "hybrid_confidence_feedback = df[df.columns[df.columns.to_series().str.contains('hybrid_confidence_feedback')]].to_numpy().T.astype(float)\n",
    "confidence = df[df.columns[(df.columns.to_series().str.contains('confidence')) & (~df.columns.to_series().str.contains('hybrid'))]].to_numpy().T.astype(float)\n",
    "confidence[confidence < 0] = np.nan\n",
    "conf_norm = (confidence-1)/3\n",
    "correctness = np.ones_like(accuracy[0])\n",
    "final_accuracy = df[df.columns[df.columns.to_series().str.contains('is_correct_final')]].to_numpy().T.astype(int)\n",
    "bci_confidence_feedback = df[df.columns[df.columns.to_series().str.contains('BCIConf_feedback')]].to_numpy().T.astype(float)\n",
    "# Majority\n",
    "maj_perf = majority(accuracy.copy(), correctness.copy(), tie_policy=\"random_balanced\", max_group_size=MAX_GROUP)\n",
    "ax = group_accuracy(maj_perf, color=\"xkcd:grey\", marker=\"o\", show_sem=True, label=\"Majority 1st decision\")\n",
    "# Reported confidence\n",
    "conf_perf = majority(accuracy.copy(), correctness.copy(), conf_norm.copy(), tie_policy=\"random_balanced\", max_group_size=MAX_GROUP)\n",
    "ax = group_accuracy(conf_perf, color=\"#c588c0\", marker=\"o\", show_sem=True, label=\"Confidence 1st decision\", ax=ax)\n",
    "# BCI confidence\n",
    "bci_perf = majority(accuracy.copy(), correctness.copy(), bci_confidence.copy(), tie_policy=\"random_balanced\", max_group_size=MAX_GROUP)\n",
    "ax = group_accuracy(bci_perf, color=\"#324daa\", marker=\"o\", show_sem=True, label=\"BCI 1st decision\", ax=ax)\n",
    "# Second decision majority\n",
    "correctness = np.ones_like(final_accuracy[0])\n",
    "maj_final_perf = majority(final_accuracy.copy(), correctness.copy(), tie_policy=\"random_balanced\", max_group_size=MAX_GROUP)\n",
    "ax = group_accuracy(maj_final_perf, color=\"xkcd:grey\", marker=\"s\", ls=\"--\", show_sem=True, label=\"Majority 2nd decision\", ax=ax)\n",
    "# Second decision BCI confidence\n",
    "bci_perf_final = majority(final_accuracy.copy(), correctness.copy(), bci_confidence_feedback.copy(), tie_policy=\"random_balanced\", max_group_size=MAX_GROUP)\n",
    "ax = group_accuracy(bci_perf_final, color=\"#324daa\", marker=\"s\", ls='--', show_sem=True, label=\"BCI 2nd decision\", ax=ax)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.yticks(range(60, 86, 5))\n",
    "plt.xlim(0.5, 14.5)\n",
    "plt.ylim(58, 85)\n",
    "plt.savefig(GROUP_RESULT_FOLDER+\"group_performance.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(statistics(maj_perf, conf_perf))\n",
    "print(statistics(maj_perf, bci_perf))\n",
    "print(statistics(conf_perf, bci_perf))\n",
    "print(statistics(bci_perf, maj_final_perf))\n",
    "print(statistics(bci_perf_final, maj_final_perf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correct vs. Incorrect response analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRONTAL = [3, 10, 16, 18, 23, 124, 4, 11, 19, 24, 118, 5, 12, 20]\n",
    "POSTERIOR = [61, 62, 78, 60, 67, 72, 77, 85, 66, 71, 76, 84, 70, 75, 83]\n",
    "LEFT = [45, 46, 50, 51, 39, 40, 41, 47, 52, 42, 36, 29, 35]\n",
    "FRONTALLEFT = [33, 39, 40, 34, 27, 26, 23, 24, 28, 35]\n",
    "RIGHT = [108, 102, 101, 97, 115, 109, 103, 98, 92, 93, 104, 111, 110]\n",
    "CENTRAL = [6, 112, 105, 87, 79, 54, 37, 30, 13, 7, 106, 80, 55, 31]\n",
    "ALL = list(range(1, 129))\n",
    "for out_of_scalp in [48, 119, 127, 128, 43, 49, 56, 63, 68, 73, 81, 88, 94, 99, 107, 113, 120, 125, 126, 17,\n",
    "                     44, 38, 32, 114, 121, 1]:\n",
    "    ALL.remove(out_of_scalp)\n",
    "LOCATIONS = [\"FRONTALLEFT\", \"FRONTAL\", \"POSTERIOR\", \"LEFT\", \"RIGHT\", \"CENTRAL\", \"ALL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = mne.read_epochs(\"%ss%d/s%d_stimulus_correct-epo.fif\" % (RESULT_FOLDER, SUBJECTS[0], SUBJECTS[0]), \n",
    "                         preload=True, verbose=False)\n",
    "for location in LOCATIONS:\n",
    "    plt.figure(figsize=(3, 3))\n",
    "    epochs.copy().pick(np.array(eval(location))-1).plot_sensors(axes=plt.gca(), show=False)\n",
    "    plt.savefig(\"%s/electrode_location_%s.pdf\" % (GROUP_RESULT_FOLDER, location.lower()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CHANNELS = 129\n",
    "SR = 100 # HZ\n",
    "EPOCH_LENGTH = 2.1  #s\n",
    "EPOCH_TYPES = {\"stimulus\": [-600, 1500], \"decision\": [-100, 2000], \"feedback\": [-100, 2000]}\n",
    "if not os.path.isdir(\"%scorrect_vs_incorrect\" % GROUP_RESULT_FOLDER):\n",
    "    os.makedirs(\"%scorrect_vs_incorrect\" % GROUP_RESULT_FOLDER)\n",
    "    for epoch in EPOCH_TYPES:\n",
    "        os.makedirs(\"%scorrect_vs_incorrect/%s_locked\" % (GROUP_RESULT_FOLDER, epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split epochs in correct and incorrect trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "behavioral_data = pd.read_csv(\"%sbehavioral_data.csv\" % GROUP_RESULT_FOLDER)\n",
    "for s, subject in enumerate(SUBJECTS):\n",
    "    for epoch_idx, epoch_label in enumerate(EPOCH_TYPES):\n",
    "        print(subject, epoch_label)\n",
    "        epochs = mne.read_epochs(\"%ss%d/s%d_%s-epo.fif\" % (RESULT_FOLDER, subject, subject, epoch_label), \n",
    "                                 preload=True, verbose=False)\n",
    "        is_rejected = np.load(\"%ss%d/s%d_is_rejected_%s.npy\" % (RESULT_FOLDER, subject, subject, epoch_label))\n",
    "        is_correct = (behavioral_data[\"Decisions_%s\" % subject] == behavioral_data[\"Correct_Answer\"]).values\n",
    "        if epoch_label == \"decision\":\n",
    "            is_correct = is_correct[behavioral_data[\"Decisions_%s\" % subject] != -1]\n",
    "        is_correct = is_correct[:is_rejected.shape[0]]\n",
    "        # Remove rejected epochs\n",
    "        is_correct = is_correct[~is_rejected]\n",
    "        assert is_correct.shape[0] == epochs.get_data().shape[0]\n",
    "        epochs[is_correct].save(\"%ss%d/s%d_%s_correct-epo.fif\" % (RESULT_FOLDER, subject, subject, epoch_label), overwrite=True, verbose=False)\n",
    "        epochs[~is_correct].save(\"%ss%d/s%d_%s_incorrect-epo.fif\" % (RESULT_FOLDER, subject, subject, epoch_label), overwrite=True, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute grand medians and Wilcoxon test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "subject_avg_correct = np.zeros((len(EPOCH_TYPES), len(SUBJECTS), N_CHANNELS, int(EPOCH_LENGTH*SR)))\n",
    "subject_avg_incorrect = np.zeros((len(EPOCH_TYPES), len(SUBJECTS), N_CHANNELS, int(EPOCH_LENGTH*SR)))\n",
    "wilcox = np.ones((len(EPOCH_TYPES), N_CHANNELS, int(EPOCH_LENGTH*SR)))\n",
    "np.random.seed(2)\n",
    "for s, subject in enumerate(SUBJECTS):\n",
    "    for epoch_idx, epoch_label in enumerate(EPOCH_TYPES):\n",
    "        correct = mne.read_epochs(\"%ss%d/s%d_%s_correct-epo.fif\" % (RESULT_FOLDER, subject, subject, epoch_label), \n",
    "                                  preload=True, verbose=False)\n",
    "        incorrect = mne.read_epochs(\"%ss%d/s%d_%s_incorrect-epo.fif\" % (RESULT_FOLDER, subject, subject, epoch_label), \n",
    "                                    preload=True, verbose=False)\n",
    "        if len(correct) > len(incorrect):\n",
    "            correct.drop(np.random.choice(range(len(correct)), replace=False, size=len(correct)-len(incorrect)))\n",
    "        elif len(correct) < len(incorrect):\n",
    "            incorrect.drop(np.random.choice(range(len(incorrect)), replace=False, size=len(incorrect)-len(correct)))\n",
    "        subject_avg_correct[epoch_idx, s, :] = correct.average(method=\"median\").data\n",
    "        subject_avg_incorrect[epoch_idx, s] = incorrect.average(method=\"median\").data\n",
    "for epoch_idx in range(len(EPOCH_TYPES)):\n",
    "    for chan in range(N_CHANNELS-1):\n",
    "        for sample in range(subject_avg_correct.shape[-1]):\n",
    "            wilcox[epoch_idx, chan-1, sample] = ss.wilcoxon(subject_avg_correct[epoch_idx, :, chan, sample], \n",
    "                                                            subject_avg_incorrect[epoch_idx, :, chan, sample])[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot grand means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for channels in [\"frontalleft\", \"posterior\"]:\n",
    "    selected_channels = np.array(eval(channels.upper()))-1\n",
    "    avg_correct = np.zeros((len(EPOCH_TYPES), len(SUBJECTS), int(EPOCH_LENGTH*SR)))\n",
    "    avg_incorrect = np.zeros((len(EPOCH_TYPES), len(SUBJECTS), int(EPOCH_LENGTH*SR)))\n",
    "    all_correct = None\n",
    "    all_incorrect = None\n",
    "    wilcox_curr = np.ones((len(EPOCH_TYPES), int(EPOCH_LENGTH*SR)))\n",
    "    np.random.seed(2)\n",
    "    subsample = 1\n",
    "    for s, subject in enumerate(SUBJECTS):\n",
    "        for epoch_idx, epoch_label in enumerate(EPOCH_TYPES):\n",
    "            correct = mne.read_epochs(\"%ss%d/s%d_%s_correct-epo.fif\" % (RESULT_FOLDER, subject, subject, epoch_label), \n",
    "                                      preload=True, verbose=False)\n",
    "            incorrect = mne.read_epochs(\"%ss%d/s%d_%s_incorrect-epo.fif\" % (RESULT_FOLDER, subject, subject, epoch_label), \n",
    "                                        preload=True, verbose=False)\n",
    "            if all_correct is None:\n",
    "                all_correct = np.median(correct._data[:, selected_channels], axis=1)\n",
    "                all_incorrect = np.median(incorrect._data[:, selected_channels], axis=1)\n",
    "            else:\n",
    "                all_correct = np.vstack((all_correct, np.median(correct._data[:, selected_channels], axis=1)))\n",
    "                all_incorrect = np.vstack((all_incorrect, np.median(incorrect._data[:, selected_channels], axis=1)))\n",
    "            # Equalize number of epochs by picking random ones\n",
    "            if len(correct) > len(incorrect):\n",
    "                correct.drop(np.random.choice(range(len(correct)), replace=False, size=len(correct)-len(incorrect)))\n",
    "            elif len(correct) < len(incorrect):\n",
    "                incorrect.drop(np.random.choice(range(len(incorrect)), replace=False, size=len(incorrect)-len(correct)))\n",
    "            avg_correct[epoch_idx, s] = np.mean(correct.average(method=\"mean\").data[selected_channels], axis=0)\n",
    "            avg_incorrect[epoch_idx, s] = np.mean(incorrect.average(method=\"mean\").data[selected_channels], axis=0)\n",
    "    all_correct = all_correct[:, 14:-50:subsample]\n",
    "    all_incorrect = all_incorrect[:, 14:-50:subsample]\n",
    "    T_obs, clusters, cluster_pv, H0 = permutation_cluster_test([all_correct, all_incorrect])\n",
    "    for epoch_idx in range(len(EPOCH_TYPES)):\n",
    "        for sample in range(avg_correct.shape[-1]):\n",
    "            wilcox_curr[epoch_idx, sample] = ss.wilcoxon(avg_correct[epoch_idx, :, sample], \n",
    "                                                         avg_incorrect[epoch_idx, :, sample])[1]\n",
    "    for epoch_idx, epoch_label in enumerate(EPOCH_TYPES):\n",
    "        fig, ax = plt.subplots(figsize=(4, 3))\n",
    "        ep_start, ep_end = EPOCH_TYPES[epoch_label]\n",
    "        abscissas = np.linspace(ep_start, ep_end, avg_correct.shape[-1])\n",
    "        ax.axhline(0, color='gray', ls=':', lw=1)\n",
    "        plt.grid(b=False)\n",
    "        plt.ylim((-8, 8.25))\n",
    "        plt.yticks(range(-8, 9, 8), fontsize=18)\n",
    "        plt.xticks(range(ep_start+100, ep_end+1, 500), range(ep_start+100+500, ep_end+1+500, 500), fontsize=18)\n",
    "        plt.xlim(ep_start+100, ep_end-500)\n",
    "        p1 = ax.plot(abscissas[14:-50:subsample], 1e6*np.median(avg_correct[epoch_idx], axis=0)[14:-50:subsample], \"-\", ms=5, label=\"Correct\", color=CORRECT_COLOR, lw=2)\n",
    "        p2 = ax.plot(abscissas[14:-50:subsample], 1e6*np.median(avg_incorrect[epoch_idx], axis=0)[14:-50:subsample], \"-\", ms=5, label=\"Incorrect\", color=INCORRECT_COLOR, lw=2)\n",
    "        for i_c, c in enumerate(clusters):\n",
    "            c = c[0]\n",
    "            print(i_c, c, cluster_pv[i_c])\n",
    "            if cluster_pv[i_c] <= 0.05:\n",
    "                h = plt.axvspan(abscissas[c[0]], abscissas[c[-1]], color='yellow', alpha=0.3)\n",
    "        where_is_significant = np.where(wilcox_curr[epoch_idx][14:-50:subsample] <= 0.05)[0]\n",
    "        plt.scatter(abscissas[14:-50:subsample][where_is_significant], [8]*len(where_is_significant), s=40, marker=(5, 2), c='k', lw=0.6)\n",
    "        plt.legend(loc=\"lower center\", ncol=2, fontsize=14)\n",
    "        plt.savefig(\"%scorrect_vs_incorrect/%s_locked/grand_mean_%s.pdf\" % (GROUP_RESULT_FOLDER, epoch_label, channels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ioff()\n",
    "for epoch_idx, epoch_label in enumerate(EPOCH_TYPES):\n",
    "    ep_start, ep_end = EPOCH_TYPES[epoch_label]\n",
    "    for electrode in range(N_CHANNELS-1):\n",
    "        fig, ax = plt.subplots()\n",
    "        abscissas = np.linspace(ep_start, ep_end, subject_avg_correct.shape[-1])\n",
    "        ax.axhline(0, color='gray', ls=':', lw=1)\n",
    "        ax.axvline(0, color='gray', ls=\":\", lw=1)\n",
    "        plt.grid(b=False)\n",
    "        plt.ylim((-10, 10.2))\n",
    "        plt.yticks(range(-10, 11, 5))\n",
    "        plt.xticks(range(ep_start+100, ep_end+1, 250), range(ep_start+100, ep_end+1, 250))\n",
    "        plt.xlim(ep_start+100, ep_end-500)\n",
    "        plt.ylabel(\"EEG amplitude (uV)\")\n",
    "        plt.xlabel(\"Time (ms)\")\n",
    "        p1 = ax.plot(abscissas, 1e6*np.median(subject_avg_correct[epoch_idx, :, electrode], axis=0), label=\"Correct\", color=CORRECT_COLOR, lw=2)\n",
    "        p2 = ax.plot(abscissas, 1e6*np.median(subject_avg_incorrect[epoch_idx, :, electrode], axis=0), label=\"Incorrect\", color=INCORRECT_COLOR, lw=2)\n",
    "        where_is_significant = np.where(wilcox[epoch_idx, electrode] < 0.05)[0]\n",
    "        plt.scatter(abscissas[where_is_significant], [10]*len(where_is_significant), s=5, marker=\"s\", c='k')\n",
    "        plt.legend(loc=\"lower left\", ncol=1)\n",
    "        plt.savefig(\"%scorrect_vs_incorrect/%s_locked/grand_avg_E%d.pdf\" % (GROUP_RESULT_FOLDER, epoch_label, electrode+1))\n",
    "        plt.clf()\n",
    "        plt.close('all')\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot scalp maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ioff()\n",
    "for epoch_idx, epoch_label in enumerate(EPOCH_TYPES):\n",
    "    ep_start, ep_end = EPOCH_TYPES[epoch_label]\n",
    "    epochs = mne.read_epochs(\"%ss%d/s%d_%s-epo.fif\" % (RESULT_FOLDER, SUBJECTS[0], SUBJECTS[0], epoch_label), \n",
    "                             preload=True, verbose=False)\n",
    "    for time in range(ep_start, ep_end, 10):\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 2.5))\n",
    "        abscissas = np.linspace(ep_start, ep_end, subject_avg_correct.shape[-1]+1)\n",
    "        im, cn = mne.viz.plot_topomap(1e6*np.median(subject_avg_correct[epoch_idx], axis=0)[:, np.where(abscissas == time)[0][0]],\n",
    "                                      pos=epochs.info, axes=ax1, sensors=False, contours=0, vmin=-10, vmax=10,\n",
    "                                      show=False, sphere=-1)\n",
    "        ax1.invert_xaxis()\n",
    "        ax1.invert_yaxis()\n",
    "        im, cn = mne.viz.plot_topomap(1e6*np.median(subject_avg_incorrect[epoch_idx], axis=0)[:, np.where(abscissas == time)[0][0]],\n",
    "                                      pos=epochs.info, axes=ax2, sensors=False, contours=0, vmin=-10, vmax=10,\n",
    "                                      show=False, sphere=-1)\n",
    "        ax2.invert_xaxis()\n",
    "        ax2.invert_yaxis()\n",
    "        plt.colorbar(im, ax=[ax1, ax2], ticks=[-10, 0, 10])\n",
    "        ax1.set_title(\"Correct\")\n",
    "        ax2.set_title(\"Incorrect\")\n",
    "        plt.savefig(\"%scorrect_vs_incorrect/%s_locked/scalp_maps_%dms.pdf\" % (GROUP_RESULT_FOLDER, epoch_label, time))\n",
    "        fig, (ax1) = plt.subplots(1, 1, figsize=(2.8, 2))\n",
    "        im, cn = mne.viz.plot_topomap(wilcox[epoch_idx, :, np.where(abscissas == time)[0][0]], cmap='RdBu', vmin=0.0, vmax=0.1,\n",
    "                                      pos=epochs.info, axes=ax1, sensors=False, contours=0, show=False, sphere=-1,\n",
    "                                      extrapolate=\"box\", res=200)\n",
    "        ax1.invert_xaxis()\n",
    "        ax1.invert_yaxis()\n",
    "        plt.colorbar(im, ax=[ax1], ticks=[0, 0.05, 0.1])\n",
    "        plt.savefig(\"%scorrect_vs_incorrect/%s_locked/scalp_maps_wilcoxon_%dms.pdf\" % (GROUP_RESULT_FOLDER, epoch_label, time))\n",
    "        plt.clf()\n",
    "        plt.close('all')\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency analysis\n",
    "Is there any power difference during the stimulus presentation that predicts correctness?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using stimulus-locked epochs, for each subject compute PSD for correct and incorrect in frontal and posterior electrodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Individual PSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.ioff()\n",
    "powers_correct = np.zeros((len(SUBJECTS), 128, 29, 210))\n",
    "powers_incorrect = np.zeros((len(SUBJECTS), 128, 29, 210))\n",
    "np.random.seed(2)\n",
    "for s, subject in enumerate(SUBJECTS):\n",
    "    print(\"Subject\", subject)\n",
    "    # Load epochs\n",
    "    correct = mne.read_epochs(\"%ss%d/s%d_stimulus_correct-epo.fif\" % (RESULT_FOLDER, subject, subject), \n",
    "                              preload=True, verbose=False)\n",
    "    incorrect = mne.read_epochs(\"%ss%d/s%d_stimulus_incorrect-epo.fif\" % (RESULT_FOLDER, subject, subject), \n",
    "                                preload=True, verbose=False)\n",
    "    # Remove Cz\n",
    "    correct = correct.drop_channels([\"Cz\"])\n",
    "    incorrect = incorrect.drop_channels([\"Cz\"])\n",
    "    # Equalize number of epochs by picking random ones\n",
    "    if len(correct) > len(incorrect):\n",
    "        correct.drop(np.random.choice(range(len(correct)), replace=False, size=len(correct)-len(incorrect)))\n",
    "    elif len(correct) < len(incorrect):\n",
    "        incorrect.drop(np.random.choice(range(len(incorrect)), replace=False, size=len(incorrect)-len(correct)))\n",
    "    # Compute PSD\n",
    "    freqs = np.arange(1., 30., 1.)\n",
    "    power_correct = mne.time_frequency.tfr_multitaper(correct, freqs=freqs, n_cycles=freqs / 4., use_fft=True,\n",
    "                                                      return_itc=False, n_jobs=8, time_bandwidth=4.0, verbose=False)\n",
    "    powers_correct[s] = power_correct.data\n",
    "    freqs = power_correct.freqs\n",
    "    times = power_correct.times\n",
    "    infos = power_correct.info\n",
    "    nave = power_correct.nave\n",
    "    power_incorrect = mne.time_frequency.tfr_multitaper(incorrect, freqs=freqs, n_cycles=freqs / 4., use_fft=True,\n",
    "                                                        return_itc=False, n_jobs=8, time_bandwidth=4.0, verbose=False)\n",
    "    powers_incorrect[s] = power_incorrect.data\n",
    "    # Plot average PSD per subject\n",
    "    if not os.path.isdir(\"%s/s%s/correct_vs_incorrect/\" % (RESULT_FOLDER, subject)):\n",
    "        os.makedirs(\"%s/s%s/correct_vs_incorrect/\" % (RESULT_FOLDER, subject))\n",
    "    for location in [\"FRONTALLEFT\", \"POSTERIOR\"]:\n",
    "        power_correct.plot(eval(location), baseline=(-0.1, 0), mode='logratio', title=\"Correct\", combine='mean',\n",
    "                           vmin=-0.6, vmax=0.6, tmin=-0.1, tmax=1.0, show=False, verbose=False)\n",
    "        plt.savefig(\"%s/s%s/correct_vs_incorrect/psd_correct_%s.pdf\" % (RESULT_FOLDER, subject, location.lower()))\n",
    "        power_incorrect.plot(eval(location), baseline=(-0.1, 0), mode='logratio', title=\"Incorrect\", combine='mean',\n",
    "                             vmin=-0.6, vmax=0.6, tmin=-0.1, tmax=1.0, show=False, verbose=False)\n",
    "        plt.savefig(\"%s/s%s/correct_vs_incorrect/psd_incorrect_%s.pdf\" % (RESULT_FOLDER, subject, location.lower()))\n",
    "        plt.clf()\n",
    "        plt.close('all')\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Group PSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_correct = mne.time_frequency.AverageTFR(info=infos, data=powers_correct.mean(axis=0),\n",
    "                                            times=times, freqs=freqs, nave=nave)\n",
    "avg_incorrect = mne.time_frequency.AverageTFR(info=infos, data=powers_incorrect.mean(axis=0),\n",
    "                                              times=times, freqs=freqs, nave=nave)\n",
    "plt.ioff()\n",
    "for location in LOCATIONS:\n",
    "    avg_correct.plot(eval(location), baseline=(-0.1, 0), mode='logratio', title=\"Correct\", combine='mean',\n",
    "                     vmin=-0.6, vmax=0.6, tmin=-0.1, tmax=1.0, show=False, verbose=False)\n",
    "    plt.savefig(\"%s/correct_vs_incorrect/stimulus_locked/psd_correct_%s.pdf\" % (GROUP_RESULT_FOLDER, location.lower()))\n",
    "    avg_incorrect.plot(eval(location), baseline=(-0.1, 0), mode='logratio', title=\"Incorrect\", combine='mean',\n",
    "                       vmin=-0.6, vmax=0.6, tmin=-0.1, tmax=1.0, show=False, verbose=False)\n",
    "    plt.savefig(\"%s/correct_vs_incorrect/stimulus_locked/psd_incorrect_%s.pdf\" % (GROUP_RESULT_FOLDER, location.lower()))\n",
    "    plt.clf()\n",
    "    plt.close('all')\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract alpha, beta, etc. power for correct and incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = [['delta', 1, 4], ['theta', 4, 8], ['alpha', 8, 13], ['beta', 13, 30]]\n",
    "means_per_subject = np.zeros((len(SUBJECTS), len(bands), len(LOCATIONS), 2))\n",
    "time_from = 0.7\n",
    "time_to = 1.4\n",
    "for l, location in enumerate(LOCATIONS):\n",
    "    if location != \"FRONTALLEFT\" and location != \"POSTERIOR\":\n",
    "        continue\n",
    "    for b, band in enumerate(bands):\n",
    "        for s in range(len(SUBJECTS)):\n",
    "            subj_correct = np.median(powers_correct[s, np.array(eval(location))-1], axis=0)\n",
    "            means_per_subject[s, b, l, 1] = 100*np.median(np.sum(subj_correct[np.logical_and(freqs >= band[1], freqs <= band[2])], axis=0)[np.logical_and(times >= time_from, times <= time_to)]) / np.median(np.sum(subj_correct, axis=0)[np.logical_and(times >= time_from, times <= time_to)])\n",
    "            subj_incorrect = np.median(powers_incorrect[s, np.array(eval(location))-1], axis=0)\n",
    "            means_per_subject[s, b, l, 0] = 100*np.median(np.sum(subj_incorrect[np.logical_and(freqs >= band[1], freqs <= band[2])], axis=0)[np.logical_and(times >= time_from, times <= time_to)]) / np.median(np.sum(subj_incorrect, axis=0)[np.logical_and(times >= time_from, times <= time_to)])\n",
    "        p = pg.wilcoxon(means_per_subject[:, b, l, 0], means_per_subject[:, b, l, 1])['p-val'].values[0]\n",
    "        df = pd.DataFrame()\n",
    "        df[\"power\"] = means_per_subject[:, b, l].flatten()\n",
    "        df[\"condition\"] = [\"Incorrect\", \"Correct\"]*len(SUBJECTS)\n",
    "        plt.figure(figsize=(2, 3))\n",
    "        sns.boxplot(data=df, x='condition', y='power', ax=plt.gca(), notch=False, width=0.9, linewidth=1.5,\n",
    "                    palette=[INCORRECT_COLOR, CORRECT_COLOR])\n",
    "        sns.swarmplot(data=df, x='condition', y='power', ax=plt.gca(), color='0.2')\n",
    "        plt.xlabel(\"\")\n",
    "        if band[0] == \"alpha\":\n",
    "            plt.yticks([15, 25, 35], fontsize=18)\n",
    "            plt.ylim(15, 35)\n",
    "        elif band[0] == \"beta\":\n",
    "            plt.yticks([0, 25, 50], fontsize=18)\n",
    "            plt.ylim(0, 50)\n",
    "        elif band[0] == \"delta\":\n",
    "            plt.yticks([10, 35, 60], fontsize=18)\n",
    "            plt.ylim(10, 60)\n",
    "        elif band[0] == \"theta\":\n",
    "            plt.yticks([20, 35, 50], fontsize=18)\n",
    "            plt.ylim(20, 50)\n",
    "        plt.xticks([])\n",
    "        plt.ylabel(\"\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"%s/correct_vs_incorrect/eeg_%s_%s.png\" % (GROUP_RESULT_FOLDER, band[0], location.lower()))\n",
    "        if p > 0.0125:\n",
    "            plt.clf()\n",
    "            plt.close()\n",
    "        else:\n",
    "            print(location, band)\n",
    "            print(pg.wilcoxon(means_per_subject[:, b, l, 0], means_per_subject[:, b, l, 1]))\n",
    "            print(pg.compute_effsize(means_per_subject[:, b, l, 0], means_per_subject[:, b, l, 1]))\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time-frequency, p-value maps for correct vs. incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvals = np.zeros((len(LOCATIONS), 29, 210))\n",
    "for f in range(29):\n",
    "    for t in range(210):\n",
    "        for l, location in enumerate(LOCATIONS):\n",
    "            pvals[l, f, t] = ss.wilcoxon(np.median(powers_correct[:, np.array(eval(location))-1, f, t], axis=1),\n",
    "                                         np.median(powers_incorrect[:, np.array(eval(location))-1, f, t], axis=1))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rts = np.loadtxt(\"%sGROUP_RESULTS/BEHAVIOR/all_rts.txt\" % RESULT_FOLDER)\n",
    "all_correct_answers = np.loadtxt(\"%sGROUP_RESULTS/BEHAVIOR/all_correct_answers.txt\" % RESULT_FOLDER)\n",
    "all_decisions = np.loadtxt(\"%sGROUP_RESULTS/BEHAVIOR/all_decisions.txt\" % RESULT_FOLDER)\n",
    "mean_rt_correct = np.mean(all_rts[np.logical_and(all_decisions == all_correct_answers, all_rts > 0)])\n",
    "mean_rt_incorrect = np.mean(all_rts[np.logical_and(all_decisions != all_correct_answers, all_rts > 0)])\n",
    "for l, location in enumerate(LOCATIONS):\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(pvals[l], cmap=\"RdBu\", vmin=0.0, vmax=0.1, interpolation=None, alpha=1, resample=False)\n",
    "    plt.xticks(range(10, 211, 25), range(0, 2001, 250), fontsize=18)\n",
    "    plt.xlim(10, 160)\n",
    "    plt.yticks(range(0, 31, 10), fontsize=18)\n",
    "    plt.grid(b=False)\n",
    "    plt.savefig(\"%s/correct_vs_incorrect/stimulus_locked/psd_wilcoxon_%s.png\" % (GROUP_RESULT_FOLDER, location.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch_idx, epoch_label in enumerate(EPOCH_TYPES):\n",
    "    all_correct = []\n",
    "    all_incorrect = []\n",
    "    for s, subject in enumerate(SUBJECTS):\n",
    "        correct = mne.read_epochs(\"%ss%d/s%d_%s_correct-epo.fif\" % (RESULT_FOLDER, subject, subject, epoch_label), \n",
    "                                  preload=True, verbose=False)\n",
    "        all_correct.append(correct)\n",
    "        incorrect = mne.read_epochs(\"%ss%d/s%d_%s_incorrect-epo.fif\" % (RESULT_FOLDER, subject, subject, epoch_label), \n",
    "                                    preload=True, verbose=False)\n",
    "        all_incorrect.append(incorrect)\n",
    "    correct = mne.epochs.concatenate_epochs(all_correct)\n",
    "    incorrect = mne.epochs.concatenate_epochs(all_incorrect)\n",
    "    correct.save(\"%scorrect_vs_incorrect/%s_locked/correct-epo.fif\" % (GROUP_RESULT_FOLDER, epoch_label), overwrite=True)\n",
    "    incorrect.save(\"%scorrect_vs_incorrect/%s_locked/incorrect-epo.fif\" % (GROUP_RESULT_FOLDER, epoch_label), overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confidence analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CHANNELS = 129\n",
    "SR = 100 # HZ\n",
    "EPOCH_LENGTH = 2.1  #s\n",
    "EPOCH_TYPES = {\"stimulus\": [-600, 1500], \"decision\": [-100, 2000], \"feedback\": [-100, 2000]}\n",
    "if not os.path.isdir(\"%sconfident_vs_notconfident\" % GROUP_RESULT_FOLDER):\n",
    "    os.makedirs(\"%sconfident_vs_notconfident\" % GROUP_RESULT_FOLDER)\n",
    "    for epoch in EPOCH_TYPES:\n",
    "        os.makedirs(\"%sconfident_vs_notconfident/%s_locked\" % (GROUP_RESULT_FOLDER, epoch))\n",
    "CONFIDENT_COLOR = \"#4dac26\"\n",
    "NOTCONFIDENT_COLOR = \"#d01c8b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behavioral_data = pd.read_csv(\"%sbehavioral_data.csv\" % GROUP_RESULT_FOLDER)\n",
    "for s, subject in enumerate(SUBJECTS):\n",
    "    for epoch_idx, epoch_label in enumerate(EPOCH_TYPES):\n",
    "        print(subject, epoch_label)\n",
    "        epochs = mne.read_epochs(\"%ss%d/s%d_%s-epo.fif\" % (RESULT_FOLDER, subject, subject, epoch_label), \n",
    "                                 preload=True, verbose=False)\n",
    "        is_rejected = np.load(\"%ss%d/s%d_is_rejected_%s.npy\" % (RESULT_FOLDER, subject, subject, epoch_label))\n",
    "        is_notconfident = ((behavioral_data[\"Confidence_%s\" % subject] == 1) | (behavioral_data[\"Confidence_%s\" % subject] == 2)).values\n",
    "        is_confident = ((behavioral_data[\"Confidence_%s\" % subject] == 3) | (behavioral_data[\"Confidence_%s\" % subject] == 4)).values\n",
    "        is_confident = is_confident[:is_rejected.shape[0]]\n",
    "        is_notconfident = is_notconfident[:is_rejected.shape[0]]\n",
    "        # Remove rejected epochs\n",
    "        is_confident = is_confident[~is_rejected]\n",
    "        is_notconfident = is_notconfident[~is_rejected]\n",
    "        assert is_confident.shape[0] == epochs.get_data().shape[0]\n",
    "        epochs[is_confident].save(\"%ss%d/s%d_%s_confident-epo.fif\" % (RESULT_FOLDER, subject, subject, epoch_label), overwrite=True, verbose=False)\n",
    "        epochs[is_notconfident].save(\"%ss%d/s%d_%s_notconfident-epo.fif\" % (RESULT_FOLDER, subject, subject, epoch_label), overwrite=True, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute grand medians and Wilcoxon test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "subject_avg_confident = np.zeros((len(EPOCH_TYPES), len(SUBJECTS), N_CHANNELS, int(EPOCH_LENGTH*SR)))\n",
    "subject_avg_notconfident = np.zeros((len(EPOCH_TYPES), len(SUBJECTS), N_CHANNELS, int(EPOCH_LENGTH*SR)))\n",
    "wilcox = np.ones((len(EPOCH_TYPES), N_CHANNELS, int(EPOCH_LENGTH*SR)))\n",
    "np.random.seed(2)\n",
    "for s, subject in enumerate(SUBJECTS):\n",
    "    for epoch_idx, epoch_label in enumerate(EPOCH_TYPES):\n",
    "        confident = mne.read_epochs(\"%ss%d/s%d_%s_confident-epo.fif\" % (RESULT_FOLDER, subject, subject, epoch_label), \n",
    "                                    preload=True, verbose=False)\n",
    "        notconfident = mne.read_epochs(\"%ss%d/s%d_%s_notconfident-epo.fif\" % (RESULT_FOLDER, subject, subject, epoch_label), \n",
    "                                       preload=True, verbose=False)\n",
    "        if len(confident) > len(notconfident):\n",
    "            confident.drop(np.random.choice(range(len(confident)), replace=False, size=len(confident)-len(notconfident)))\n",
    "        elif len(confident) < len(notconfident):\n",
    "            notconfident.drop(np.random.choice(range(len(notconfident)), replace=False, size=len(notconfident)-len(confident)))\n",
    "        subject_avg_confident[epoch_idx, s, :] = confident.average(method=\"median\").data\n",
    "        subject_avg_notconfident[epoch_idx, s] = notconfident.average(method=\"median\").data\n",
    "for epoch_idx in range(len(EPOCH_TYPES)):\n",
    "    for chan in range(N_CHANNELS-1):\n",
    "        for sample in range(subject_avg_confident.shape[-1]):\n",
    "            wilcox[epoch_idx, chan-1, sample] = ss.wilcoxon(subject_avg_confident[epoch_idx, :, chan, sample], \n",
    "                                                            subject_avg_notconfident[epoch_idx, :, chan, sample])[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot grand medians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for channels in [\"frontalleft\", \"posterior\"]:\n",
    "    selected_channels = np.array(eval(channels.upper()))-1\n",
    "    avg_confident = np.zeros((len(EPOCH_TYPES), len(SUBJECTS), int(EPOCH_LENGTH*SR)))\n",
    "    avg_notconfident = np.zeros((len(EPOCH_TYPES), len(SUBJECTS), int(EPOCH_LENGTH*SR)))\n",
    "    wilcox_curr = np.ones((len(EPOCH_TYPES), int(EPOCH_LENGTH*SR)))\n",
    "    all_confident = None\n",
    "    all_notconfident = None\n",
    "    np.random.seed(2)\n",
    "    subsample = 2\n",
    "    for s, subject in enumerate(SUBJECTS):\n",
    "        for epoch_idx, epoch_label in enumerate(EPOCH_TYPES):\n",
    "            confident = mne.read_epochs(\"%ss%d/s%d_%s_confident-epo.fif\" % (RESULT_FOLDER, subject, subject, epoch_label), \n",
    "                                        preload=True, verbose=False)\n",
    "            notconfident = mne.read_epochs(\"%ss%d/s%d_%s_notconfident-epo.fif\" % (RESULT_FOLDER, subject, subject, epoch_label), \n",
    "                                           preload=True, verbose=False)\n",
    "            if all_confident is None:\n",
    "                all_confident = np.median(confident._data[:, selected_channels], axis=1)\n",
    "                all_notconfident = np.median(notconfident._data[:, selected_channels], axis=1)\n",
    "            else:\n",
    "                all_confident = np.vstack((all_confident, np.median(confident._data[:, selected_channels], axis=1)))\n",
    "                all_notconfident = np.vstack((all_notconfident, np.median(notconfident._data[:, selected_channels], axis=1)))\n",
    "            # Equalize number of epochs by picking random ones\n",
    "            if len(confident) > len(notconfident):\n",
    "                confident.drop(np.random.choice(range(len(confident)), replace=False, size=len(confident)-len(notconfident)))\n",
    "            elif len(confident) < len(notconfident):\n",
    "                notconfident.drop(np.random.choice(range(len(notconfident)), replace=False, size=len(notconfident)-len(confident)))\n",
    "            avg_confident[epoch_idx, s] = np.median(confident.average(method=\"median\").data[selected_channels], axis=0)\n",
    "            avg_notconfident[epoch_idx, s] = np.median(notconfident.average(method=\"median\").data[selected_channels], axis=0)\n",
    "    all_confident = all_confident[:, 14:-50:subsample]\n",
    "    all_notconfident = all_notconfident[:, 14:-50:subsample]\n",
    "    T_obs, clusters, cluster_pv, H0 = permutation_cluster_test([all_confident, all_notconfident])\n",
    "    for epoch_idx in range(len(EPOCH_TYPES)):\n",
    "        for sample in range(avg_confident.shape[-1]):\n",
    "            wilcox_curr[epoch_idx, sample] = ss.wilcoxon(avg_confident[epoch_idx, :, sample], \n",
    "                                                         avg_notconfident[epoch_idx, :, sample])[1]\n",
    "    for epoch_idx, epoch_label in enumerate(EPOCH_TYPES):\n",
    "        fig, ax = plt.subplots(figsize=(4, 3))\n",
    "        ep_start, ep_end = EPOCH_TYPES[epoch_label]\n",
    "        abscissas = np.linspace(ep_start, ep_end, avg_confident.shape[-1])\n",
    "        ax.axhline(0, color='gray', ls=':', lw=1)\n",
    "        plt.grid(b=False)\n",
    "        plt.ylim((-8, 8.25))\n",
    "        plt.yticks(range(-8, 9, 8), fontsize=18)\n",
    "        plt.xticks(range(ep_start+100, ep_end+1, 500), range(ep_start+100+500, ep_end+1+500, 500), fontsize=18)\n",
    "        plt.xlim(ep_start+100, ep_end-500)\n",
    "        p1 = ax.plot(abscissas[14:-50:subsample], 1e6*np.median(avg_confident[epoch_idx], axis=0)[14:-50:subsample], \"-\", ms=5, label=\"Confident\", color=CONFIDENT_COLOR, lw=2)\n",
    "        p2 = ax.plot(abscissas[14:-50:subsample], 1e6*np.median(avg_notconfident[epoch_idx], axis=0)[14:-50:subsample], \"-\", ms=5, label=\"Not confident\", color=NOTCONFIDENT_COLOR, lw=2)\n",
    "        for i_c, c in enumerate(clusters):\n",
    "            c = c[0]\n",
    "            print(i_c, c, cluster_pv[i_c])\n",
    "            if cluster_pv[i_c] <= 0.05:\n",
    "                h = plt.axvspan(abscissas[c[0]], abscissas[c[-1]], color='yellow', alpha=0.3)\n",
    "        where_is_significant = np.where(wilcox_curr[epoch_idx][14:-50:subsample] <= 0.05)[0]\n",
    "        plt.scatter(abscissas[14:-50:subsample][where_is_significant], [8]*len(where_is_significant), s=40, marker=(5, 2), c='k', lw=0.6)\n",
    "        plt.legend(loc=\"lower center\", ncol=2, fontsize=14)\n",
    "        plt.savefig(\"%sconfident_vs_notconfident/%s_locked/grand_median_%s.pdf\" % (GROUP_RESULT_FOLDER, epoch_label, channels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot scalp maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ioff()\n",
    "for epoch_idx, epoch_label in enumerate(EPOCH_TYPES):\n",
    "    ep_start, ep_end = EPOCH_TYPES[epoch_label]\n",
    "    epochs = mne.read_epochs(\"%ss%d/s%d_%s-epo.fif\" % (RESULT_FOLDER, SUBJECTS[0], SUBJECTS[0], epoch_label), \n",
    "                             preload=True, verbose=False)\n",
    "    for time in range(ep_start, ep_end, 10):\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 2.5))\n",
    "        abscissas = np.linspace(ep_start, ep_end, subject_avg_confident.shape[-1]+1)\n",
    "        im, cn = mne.viz.plot_topomap(1e6*np.median(subject_avg_confident[epoch_idx], axis=0)[:, np.where(abscissas == time)[0][0]],\n",
    "                                      pos=epochs.info, axes=ax1, sensors=False, contours=0, vmin=-10, vmax=10,\n",
    "                                      show=False, sphere=-1)\n",
    "        ax1.invert_xaxis()\n",
    "        ax1.invert_yaxis()\n",
    "        im, cn = mne.viz.plot_topomap(1e6*np.median(subject_avg_notconfident[epoch_idx], axis=0)[:, np.where(abscissas == time)[0][0]],\n",
    "                                      pos=epochs.info, axes=ax2, sensors=False, contours=0, vmin=-10, vmax=10,\n",
    "                                      show=False, sphere=-1)\n",
    "        ax2.invert_xaxis()\n",
    "        ax2.invert_yaxis()\n",
    "        plt.colorbar(im, ax=[ax1, ax2], ticks=[-10, 0, 10])\n",
    "        ax1.set_title(\"Confident\")\n",
    "        ax2.set_title(\"Not confident\")\n",
    "        plt.savefig(\"%sconfident_vs_notconfident/%s_locked/scalp_maps_%dms.pdf\" % (GROUP_RESULT_FOLDER, epoch_label, time))\n",
    "        fig, (ax1) = plt.subplots(1, 1, figsize=(2.8, 2))\n",
    "        im, cn = mne.viz.plot_topomap(wilcox[epoch_idx, :, np.where(abscissas == time)[0][0]], cmap='RdBu', vmin=0.0, vmax=0.1,\n",
    "                                      pos=epochs.info, axes=ax1, sensors=False, contours=0, show=False, sphere=-1,\n",
    "                                      extrapolate=\"box\", res=200)\n",
    "        ax1.invert_xaxis()\n",
    "        ax1.invert_yaxis()\n",
    "        plt.colorbar(im, ax=[ax1], ticks=[0, 0.05, 0.1])\n",
    "        plt.savefig(\"%sconfident_vs_notconfident/%s_locked/scalp_maps_wilcoxon_%dms.pdf\" % (GROUP_RESULT_FOLDER, epoch_label, time))\n",
    "        plt.clf()\n",
    "        plt.close('all')\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency analysis\n",
    "Is there any power difference during the stimulus presentation that predicts confidence?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Individual PSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.ioff()\n",
    "powers_confident = np.zeros((len(SUBJECTS), 128, 29, 210))\n",
    "powers_notconfident = np.zeros((len(SUBJECTS), 128, 29, 210))\n",
    "np.random.seed(2)\n",
    "for s, subject in enumerate(SUBJECTS):\n",
    "    print(\"Subject\", subject)\n",
    "    # Load epochs\n",
    "    confident = mne.read_epochs(\"%ss%d/s%d_stimulus_confident-epo.fif\" % (RESULT_FOLDER, subject, subject), \n",
    "                              preload=True, verbose=False)\n",
    "    notconfident = mne.read_epochs(\"%ss%d/s%d_stimulus_notconfident-epo.fif\" % (RESULT_FOLDER, subject, subject), \n",
    "                                preload=True, verbose=False)\n",
    "    # Remove Cz\n",
    "    confident = confident.drop_channels([\"Cz\"])\n",
    "    notconfident = notconfident.drop_channels([\"Cz\"])\n",
    "    # Equalize number of epochs by picking random ones\n",
    "    if len(confident) > len(notconfident):\n",
    "        confident.drop(np.random.choice(range(len(confident)), replace=False, size=len(confident)-len(notconfident)))\n",
    "    elif len(correct) < len(incorrect):\n",
    "        notconfident.drop(np.random.choice(range(len(notconfident)), replace=False, size=len(notconfident)-len(confident)))\n",
    "    # Compute PSD\n",
    "    freqs = np.arange(1., 30., 1.)\n",
    "    power_confident = mne.time_frequency.tfr_multitaper(confident, freqs=freqs, n_cycles=freqs / 4., use_fft=True,\n",
    "                                                      return_itc=False, n_jobs=8, time_bandwidth=4.0, verbose=False)\n",
    "    powers_confident[s] = power_confident.data\n",
    "    freqs = power_confident.freqs\n",
    "    times = power_confident.times\n",
    "    infos = power_confident.info\n",
    "    nave = power_confident.nave\n",
    "    power_notconfident = mne.time_frequency.tfr_multitaper(notconfident, freqs=freqs, n_cycles=freqs / 4., use_fft=True,\n",
    "                                                        return_itc=False, n_jobs=8, time_bandwidth=4.0, verbose=False)\n",
    "    powers_notconfident[s] = power_notconfident.data\n",
    "    # Plot average PSD per subject\n",
    "    if not os.path.isdir(\"%s/s%s/confident_vs_notconfident/\" % (RESULT_FOLDER, subject)):\n",
    "        os.makedirs(\"%s/s%s/confident_vs_notconfident/\" % (RESULT_FOLDER, subject))\n",
    "    for location in [\"FRONTALLEFT\", \"POSTERIOR\"]:\n",
    "        power_confident.plot(eval(location), baseline=(-0.1, 0), mode='logratio', title=\"Confident\", combine='mean',\n",
    "                           vmin=-0.6, vmax=0.6, tmin=-0.1, tmax=1.0, show=False, verbose=False)\n",
    "        plt.savefig(\"%s/s%s/confident_vs_notconfident/psd_confident_%s.pdf\" % (RESULT_FOLDER, subject, location.lower()))\n",
    "        power_notconfident.plot(eval(location), baseline=(-0.1, 0), mode='logratio', title=\"Not confident\", combine='mean',\n",
    "                             vmin=-0.6, vmax=0.6, tmin=-0.1, tmax=1.0, show=False, verbose=False)\n",
    "        plt.savefig(\"%s/s%s/confident_vs_notconfident/psd_notconfident_%s.pdf\" % (RESULT_FOLDER, subject, location.lower()))\n",
    "        plt.clf()\n",
    "        plt.close('all')\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Group PSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_confident = mne.time_frequency.AverageTFR(info=infos, data=powers_confident.mean(axis=0),\n",
    "                                              times=times, freqs=freqs, nave=nave)\n",
    "avg_notconfident = mne.time_frequency.AverageTFR(info=infos, data=powers_notconfident.mean(axis=0),\n",
    "                                                 times=times, freqs=freqs, nave=nave)\n",
    "plt.ioff()\n",
    "for location in LOCATIONS:\n",
    "    avg_confident.plot(eval(location), baseline=(-0.1, 0), mode='logratio', title=\"Confident\", combine='mean',\n",
    "                       vmin=-0.6, vmax=0.6, tmin=-0.1, tmax=1.0, show=False, verbose=False)\n",
    "    plt.savefig(\"%s/confident_vs_notconfident/stimulus_locked/psd_confident_%s.pdf\" % (GROUP_RESULT_FOLDER, location.lower()))\n",
    "    avg_notconfident.plot(eval(location), baseline=(-0.1, 0), mode='logratio', title=\"Not confident\", combine='mean',\n",
    "                          vmin=-0.6, vmax=0.6, tmin=-0.1, tmax=1.0, show=False, verbose=False)\n",
    "    plt.savefig(\"%s/confident_vs_notconfident/stimulus_locked/psd_notconfident_%s.pdf\" % (GROUP_RESULT_FOLDER, location.lower()))\n",
    "    plt.clf()\n",
    "    plt.close('all')\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time-frequency, p-value maps for correct vs. incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvals = np.zeros((len(LOCATIONS), 29, 210))\n",
    "for f in range(29):\n",
    "    for t in range(210):\n",
    "        for l, location in enumerate(LOCATIONS):\n",
    "            pvals[l, f, t] = ss.wilcoxon(np.median(powers_confident[:, np.array(eval(location))-1, f, t], axis=1),\n",
    "                                         np.median(powers_notconfident[:, np.array(eval(location))-1, f, t], axis=1))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l, location in enumerate(LOCATIONS):\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(pvals[l], cmap=\"RdBu\", vmin=0.0, vmax=0.1, interpolation=None, alpha=1, resample=False)\n",
    "    plt.xticks(range(10, 211, 25), range(0, 2001, 250), fontsize=18)\n",
    "    plt.xlim(10, 160)\n",
    "    plt.yticks(range(0, 31, 10), fontsize=18)\n",
    "    plt.grid(b=False)\n",
    "    plt.savefig(\"%s/confident_vs_notconfident/stimulus_locked/psd_wilcoxon_%s.png\" % (GROUP_RESULT_FOLDER, location.lower()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alpha, beta ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = [['delta', 1, 4], ['theta', 4, 8], ['alpha', 8, 13], ['beta', 13, 30]]\n",
    "means_per_subject = np.zeros((len(SUBJECTS), len(bands), len(LOCATIONS), 2))\n",
    "time_from = 0.9\n",
    "time_to = 1.45\n",
    "for l, location in enumerate(LOCATIONS):\n",
    "    if location != \"FRONTALLEFT\" and location != \"POSTERIOR\":\n",
    "        continue\n",
    "    for b, band in enumerate(bands):\n",
    "        for s in range(len(SUBJECTS)):\n",
    "            subj_confident = np.median(powers_confident[s, np.array(eval(location))-1], axis=0)\n",
    "            means_per_subject[s, b, l, 1] = 100*np.median(np.sum(subj_confident[np.logical_and(freqs >= band[1], freqs <= band[2])], axis=0)[np.logical_and(times >= time_from, times <= time_to)]) / np.median(np.sum(subj_confident, axis=0)[np.logical_and(times >= time_from, times <= time_to)])\n",
    "            subj_notconfident = np.median(powers_notconfident[s, np.array(eval(location))-1], axis=0)\n",
    "            means_per_subject[s, b, l, 0] = 100*np.median(np.sum(subj_notconfident[np.logical_and(freqs >= band[1], freqs <= band[2])], axis=0)[np.logical_and(times >= time_from, times <= time_to)]) / np.median(np.sum(subj_notconfident, axis=0)[np.logical_and(times >= time_from, times <= time_to)])\n",
    "        p = pg.wilcoxon(means_per_subject[:, b, l, 0], means_per_subject[:, b, l, 1])['p-val'].values[0]\n",
    "        df = pd.DataFrame()\n",
    "        df[\"power\"] = means_per_subject[:, b, l].flatten()\n",
    "        df[\"condition\"] = [\"Not confident\", \"Confident\"]*len(SUBJECTS)\n",
    "        plt.figure(figsize=(2, 3))\n",
    "        sns.boxplot(data=df, x='condition', y='power', ax=plt.gca(), notch=False, width=0.9, linewidth=1.5,\n",
    "                    palette=[NOTCONFIDENT_COLOR, CONFIDENT_COLOR])\n",
    "        sns.swarmplot(data=df, x='condition', y='power', ax=plt.gca(), color='0.2')\n",
    "        plt.xlabel(\"\")\n",
    "        if band[0] == \"alpha\":\n",
    "            plt.yticks([15, 25, 35], fontsize=18)\n",
    "            plt.ylim(15, 35)\n",
    "        elif band[0] == \"beta\":\n",
    "            plt.yticks([0, 25, 50], fontsize=18)\n",
    "            plt.ylim(0, 50)\n",
    "        elif band[0] == \"delta\":\n",
    "            plt.yticks([10, 35, 60], fontsize=18)\n",
    "            plt.ylim(10, 60)\n",
    "        elif band[0] == \"theta\":\n",
    "            plt.yticks([20, 35, 50], fontsize=18)\n",
    "            plt.ylim(20, 50)\n",
    "        plt.xticks([])\n",
    "        plt.ylabel(\"\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"%s/confident_vs_notconfident/eeg_%s_%s.png\" % (GROUP_RESULT_FOLDER, band[0], location.lower()))\n",
    "        if p > 0.0125:\n",
    "            plt.clf()\n",
    "            plt.close()\n",
    "        else:\n",
    "            print(location, band)\n",
    "            print(pg.wilcoxon(means_per_subject[:, b, l, 0], means_per_subject[:, b, l, 1]))\n",
    "            print(pg.compute_effsize(means_per_subject[:, b, l, 0], means_per_subject[:, b, l, 1]))\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feedback analysis\n",
    "Group trials on the basis of change of mind and agreement between user and agent. Then, plot the ERPs during the presentation of the feedback."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trust is measured by agreement and change of mind (no confidence involved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_trust(decisions_subject, decisions_agent, final_decisions):\n",
    "    return np.logical_or(np.logical_and(decisions_subject == decisions_agent, decisions_subject == final_decisions),\n",
    "                         np.logical_and(decisions_subject != decisions_agent, decisions_subject != final_decisions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CHANNELS = 129\n",
    "SR = 100 # HZ\n",
    "EPOCH_LENGTH = 2.1  #s\n",
    "EPOCH_TYPES = {\"stimulus\": [-600, 1500], \"decision\": [-100, 2000], \"feedback\": [-100, 2000]}\n",
    "DISTRUST_COLOR = \"#e66101\"\n",
    "TRUST_COLOR = \"#5e3c99\"\n",
    "if not os.path.isdir(\"%strust_vs_distrust\" % GROUP_RESULT_FOLDER):\n",
    "    os.makedirs(\"%strust_vs_distrust\" % GROUP_RESULT_FOLDER, exist_ok=True)\n",
    "    for epoch in EPOCH_TYPES:\n",
    "        os.makedirs(\"%strust_vs_distrust/%s_locked\" % (GROUP_RESULT_FOLDER, epoch), exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split epochs in correct and incorrect trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behavioral_data = pd.read_csv(\"%sbehavioral_data.csv\" % GROUP_RESULT_FOLDER)\n",
    "for s, subject in enumerate(SUBJECTS):\n",
    "    for epoch_idx, epoch_label in enumerate(EPOCH_TYPES):\n",
    "        print(subject, epoch_label)\n",
    "        epochs = mne.read_epochs(\"%ss%d/s%d_%s-epo.fif\" % (RESULT_FOLDER, subject, subject, epoch_label), \n",
    "                                 preload=True, verbose=False)\n",
    "        is_rejected = np.load(\"%ss%d/s%d_is_rejected_%s.npy\" % (RESULT_FOLDER, subject, subject, epoch_label))\n",
    "        is_trust = compute_trust(behavioral_data[\"Decisions_%s\" % subject], \n",
    "                                 behavioral_data[\"Decisions_Agent\"], \n",
    "                                 behavioral_data[\"Final_Decisions_%s\" % subject])\n",
    "        # Remove rejected epochs\n",
    "        is_trust = is_trust[:is_rejected.shape[0]]\n",
    "        is_trust = is_trust[~is_rejected]\n",
    "        assert is_trust.shape[0] == epochs.get_data().shape[0]\n",
    "        epochs[is_trust].save(\"%ss%d/s%d_%s_trust-epo.fif\" % (RESULT_FOLDER, subject, subject, epoch_label), overwrite=True, verbose=False)\n",
    "        epochs[~is_trust].save(\"%ss%d/s%d_%s_distrust-epo.fif\" % (RESULT_FOLDER, subject, subject, epoch_label), overwrite=True, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_averages_trust = np.zeros((len(EPOCH_TYPES), len(SUBJECTS), N_CHANNELS, int(EPOCH_LENGTH*SR)))\n",
    "subject_averages_distrust = np.zeros((len(EPOCH_TYPES), len(SUBJECTS), N_CHANNELS, int(EPOCH_LENGTH*SR)))\n",
    "wilcox_trust = np.ones((len(EPOCH_TYPES), N_CHANNELS, int(EPOCH_LENGTH*SR)))\n",
    "for s, subject in enumerate(SUBJECTS):\n",
    "    for epoch_idx, epoch_label in enumerate(EPOCH_TYPES):\n",
    "        trust = mne.read_epochs(\"%ss%d/s%d_%s_trust-epo.fif\" % (RESULT_FOLDER, subject, subject, epoch_label), \n",
    "                                preload=True, verbose=False)\n",
    "        distrust = mne.read_epochs(\"%ss%d/s%d_%s_distrust-epo.fif\" % (RESULT_FOLDER, subject, subject, epoch_label), \n",
    "                                   preload=True, verbose=False)\n",
    "        subject_averages_trust[epoch_idx, s, :] = trust.average(method=\"median\").data\n",
    "        subject_averages_distrust[epoch_idx, s] = distrust.average(method=\"median\").data\n",
    "for epoch_idx in range(len(EPOCH_TYPES)):\n",
    "    for chan in range(N_CHANNELS-1):\n",
    "        for sample in range(subject_averages_trust.shape[-1]):\n",
    "            wilcox_trust[epoch_idx, chan-1, sample] = ss.wilcoxon(subject_averages_trust[epoch_idx, :, chan, sample], \n",
    "                                                                  subject_averages_distrust[epoch_idx, :, chan, sample])[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot grand averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ioff()\n",
    "for epoch_idx, epoch_label in enumerate(EPOCH_TYPES):\n",
    "    ep_start, ep_end = EPOCH_TYPES[epoch_label]\n",
    "    for electrode in range(N_CHANNELS-1):\n",
    "        fig, ax = plt.subplots()\n",
    "        abscissas = np.linspace(ep_start, ep_end, subject_averages_trust.shape[-1])\n",
    "        ax.axhline(0, color='gray', ls=':', lw=1)\n",
    "        ax.axvline(0, color='gray', ls=\":\", lw=1)\n",
    "        plt.grid(b=False)\n",
    "        plt.ylim((-15, 15.2))\n",
    "        plt.yticks(range(-15, 16, 5))\n",
    "        plt.xticks(range(ep_start, ep_end+1, 100), range(ep_start, ep_end+1, 100))\n",
    "        plt.xlim(0, 1000)\n",
    "        plt.ylabel(\"EEG amplitude (uV)\")\n",
    "        plt.xlabel(\"Time (ms)\")\n",
    "        p1 = ax.plot(abscissas, 1e6*np.median(subject_averages_trust[epoch_idx, :, electrode], axis=0), label=\"Trust\", color=TRUST_COLOR, lw=2)\n",
    "        p2 = ax.plot(abscissas, 1e6*np.median(subject_averages_distrust[epoch_idx, :, electrode], axis=0), label=\"Distrust\", color=DISTRUST_COLOR, lw=2)\n",
    "        where_is_significant = np.where(wilcox_trust[epoch_idx, electrode] < 0.05)[0]\n",
    "        plt.scatter(abscissas[where_is_significant], [15]*len(where_is_significant), s=5, marker=\"s\", c='k')\n",
    "        plt.legend(loc=\"lower right\", ncol=1)\n",
    "        plt.savefig(\"%strust_vs_distrust/%s_locked/grand_avg_E%d.pdf\" % (GROUP_RESULT_FOLDER, epoch_label, electrode+1))\n",
    "        plt.clf()\n",
    "        plt.close('all')\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for channels in ['central', 'posterior']:\n",
    "    selected_channels = np.array(eval(channels.upper()))-1\n",
    "    avg_trust = np.zeros((len(EPOCH_TYPES), len(SUBJECTS), int(EPOCH_LENGTH*SR)))\n",
    "    avg_distrust = np.zeros((len(EPOCH_TYPES), len(SUBJECTS), int(EPOCH_LENGTH*SR)))\n",
    "    wilcox_curr = np.ones((len(EPOCH_TYPES), int(EPOCH_LENGTH*SR)))\n",
    "    np.random.seed(2)\n",
    "    subsample = 2\n",
    "    for s, subject in enumerate(SUBJECTS):\n",
    "        for epoch_idx, epoch_label in enumerate(EPOCH_TYPES):\n",
    "            trust = mne.read_epochs(\"%ss%d/s%d_%s_trust-epo.fif\" % (RESULT_FOLDER, subject, subject, epoch_label), \n",
    "                                      preload=True, verbose=False)\n",
    "            distrust = mne.read_epochs(\"%ss%d/s%d_%s_distrust-epo.fif\" % (RESULT_FOLDER, subject, subject, epoch_label), \n",
    "                                        preload=True, verbose=False)\n",
    "            # Equalize number of epochs by picking random ones\n",
    "            if len(trust) > len(distrust):\n",
    "                trust.drop(np.random.choice(range(len(trust)), replace=False, size=len(trust)-len(distrust)))\n",
    "            elif len(trust) < len(distrust):\n",
    "                distrust.drop(np.random.choice(range(len(distrust)), replace=False, size=len(distrust)-len(trust)))\n",
    "            avg_trust[epoch_idx, s] = np.median(trust.average(method=\"median\").data[selected_channels], axis=0)\n",
    "            avg_distrust[epoch_idx, s] = np.median(distrust.average(method=\"median\").data[selected_channels], axis=0)\n",
    "    for epoch_idx in range(len(EPOCH_TYPES)):\n",
    "        for sample in range(avg_trust.shape[-1]):\n",
    "            wilcox_curr[epoch_idx, sample] = ss.wilcoxon(avg_trust[epoch_idx, :, sample], \n",
    "                                                         avg_distrust[epoch_idx, :, sample])[1]\n",
    "\n",
    "    for epoch_idx, epoch_label in enumerate(EPOCH_TYPES):\n",
    "        if \"feedback\" not in epoch_label:\n",
    "            continue\n",
    "        fig, ax = plt.subplots(figsize=(4, 3))\n",
    "        ep_start, ep_end = EPOCH_TYPES[epoch_label]\n",
    "        abscissas = np.linspace(ep_start, ep_end, avg_trust.shape[-1])\n",
    "        ax.axhline(0, color='gray', ls=':', lw=1)\n",
    "        plt.grid(b=False)\n",
    "        plt.ylim((-4, 4.25))\n",
    "        plt.yticks(range(-4, 5, 4), fontsize=18)\n",
    "        if epoch_label == 'stimulus':\n",
    "            plt.xticks(range(ep_start+100, ep_end+1, 500), range(ep_start+100+500, ep_end+1+500, 500), fontsize=18)\n",
    "        else:\n",
    "            plt.xticks(range(ep_start+100, ep_end+1, 500), range(ep_start+100, ep_end+1, 500), fontsize=18)\n",
    "        plt.xlim(ep_start+100, ep_end-500)\n",
    "        p1 = ax.plot(abscissas[14:-50:subsample], 1e6*np.median(avg_trust[epoch_idx], axis=0)[14:-50:subsample], \"-\", ms=5, label=\"Trust\", color=TRUST_COLOR, lw=2)\n",
    "        p2 = ax.plot(abscissas[14:-50:subsample], 1e6*np.median(avg_distrust[epoch_idx], axis=0)[14:-50:subsample], \"-\", ms=5, label=\"Distrust\", color=DISTRUST_COLOR, lw=2)\n",
    "        where_is_significant = np.where(wilcox_curr[epoch_idx][14:-50:subsample] < 0.05)[0]\n",
    "        plt.scatter(abscissas[14:-50:subsample][where_is_significant], [4]*len(where_is_significant), s=40, marker=(5, 2), c='k', lw=0.75)\n",
    "        plt.legend(loc=\"lower center\", ncol=2, fontsize=14)\n",
    "        plt.savefig(\"%strust_vs_distrust/%s_locked/grand_median_%s.pdf\" % (GROUP_RESULT_FOLDER, epoch_label, channels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot scalp maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ioff()\n",
    "for epoch_idx, epoch_label in enumerate(EPOCH_TYPES):\n",
    "    ep_start, ep_end = EPOCH_TYPES[epoch_label]\n",
    "    for time in range(ep_start, ep_end, 10):\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 2.5))\n",
    "        abscissas = np.linspace(ep_start, ep_end, subject_averages_trust.shape[-1]+1)\n",
    "        im, cn = mne.viz.plot_topomap(1e6*np.median(subject_averages_trust[epoch_idx], axis=0)[:, np.where(abscissas == time)[0][0]],\n",
    "                                      pos=epochs.info, axes=ax1, sensors=False, contours=0, vmin=-10, vmax=10,\n",
    "                                      show=False, sphere=-1)\n",
    "        ax1.invert_xaxis()\n",
    "        ax1.invert_yaxis()\n",
    "        im, cn = mne.viz.plot_topomap(1e6*np.median(subject_averages_distrust[epoch_idx], axis=0)[:, np.where(abscissas == time)[0][0]],\n",
    "                                      pos=epochs.info, axes=ax2, sensors=False, contours=0, vmin=-10, vmax=10,\n",
    "                                      show=False, sphere=-1)\n",
    "        ax2.invert_xaxis()\n",
    "        ax2.invert_yaxis()\n",
    "        plt.colorbar(im, ax=[ax1, ax2], ticks=[-10, 0, 10])\n",
    "        ax1.set_title(\"Trust\")\n",
    "        ax2.set_title(\"Distrust\")\n",
    "        plt.savefig(\"%strust_vs_distrust/%s_locked/scalp_maps_%dms.pdf\" % (GROUP_RESULT_FOLDER, epoch_label, time))\n",
    "        fig, (ax1) = plt.subplots(1, 1, figsize=(2.8, 2))\n",
    "        im, cn = mne.viz.plot_topomap(wilcox_trust[epoch_idx, :, np.where(abscissas == time)[0][0]], cmap='RdBu', vmin=0.0, vmax=0.1,\n",
    "                                      pos=epochs.info, axes=ax1, sensors=False, contours=0, show=False, sphere=-1,\n",
    "                                      extrapolate=\"box\", res=200)\n",
    "        ax1.invert_xaxis()\n",
    "        ax1.invert_yaxis()\n",
    "        plt.colorbar(im, ax=[ax1], ticks=[0, 0.05, 0.1])\n",
    "        plt.savefig(\"%strust_vs_distrust/%s_locked/scalp_maps_wilcoxon_%dms.pdf\" % (GROUP_RESULT_FOLDER, epoch_label, time))\n",
    "        plt.clf()\n",
    "        plt.close('all')\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "powers_trust = np.zeros((len(SUBJECTS), 128, 29, 210))\n",
    "powers_distrust = np.zeros((len(SUBJECTS), 128, 29, 210))\n",
    "np.random.seed(2)\n",
    "for s, subject in enumerate(SUBJECTS):\n",
    "    print(\"Subject\", subject)\n",
    "    # Load epochs\n",
    "    trust = mne.read_epochs(\"%ss%d/s%d_feedback_trust-epo.fif\" % (RESULT_FOLDER, subject, subject), \n",
    "                              preload=True, verbose=False)\n",
    "    distrust = mne.read_epochs(\"%ss%d/s%d_feedback_distrust-epo.fif\" % (RESULT_FOLDER, subject, subject), \n",
    "                                preload=True, verbose=False)\n",
    "    # Remove Cz\n",
    "    trust = trust.drop_channels([\"Cz\"])\n",
    "    distrust = distrust.drop_channels([\"Cz\"])\n",
    "    # Equalize number of epochs by picking random ones\n",
    "    if len(trust) > len(distrust):\n",
    "        trust.drop(np.random.choice(range(len(trust)), replace=False, size=len(trust)-len(distrust)))\n",
    "    elif len(trust) < len(distrust):\n",
    "        distrust.drop(np.random.choice(range(len(distrust)), replace=False, size=len(distrust)-len(trust)))\n",
    "    # Compute PSD\n",
    "    freqs = np.arange(1., 30., 1.)\n",
    "    power_trust = mne.time_frequency.tfr_multitaper(trust, freqs=freqs, n_cycles=freqs / 4., use_fft=True,\n",
    "                                                      return_itc=False, n_jobs=8, time_bandwidth=4.0, verbose=False)\n",
    "    powers_trust[s] = power_trust.data\n",
    "    freqs = power_trust.freqs\n",
    "    times = power_trust.times\n",
    "    infos = power_trust.info\n",
    "    nave = power_trust.nave\n",
    "    power_distrust = mne.time_frequency.tfr_multitaper(distrust, freqs=freqs, n_cycles=freqs / 4., use_fft=True,\n",
    "                                                        return_itc=False, n_jobs=8, time_bandwidth=4.0, verbose=False)\n",
    "    powers_distrust[s] = power_distrust.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvals = np.zeros((len(LOCATIONS), 29, 210))\n",
    "for f in range(29):\n",
    "    for t in range(210):\n",
    "        for l, location in enumerate(LOCATIONS):\n",
    "            pvals[l, f, t] = ss.wilcoxon(np.median(powers_trust[:, np.array(eval(location))-1, f, t], axis=1),\n",
    "                                         np.median(powers_distrust[:, np.array(eval(location))-1, f, t], axis=1))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l, location in enumerate(LOCATIONS):\n",
    "    print(location)\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(pvals[l], cmap=\"RdBu\", vmin=0.0, vmax=0.1, interpolation=None, alpha=1, resample=False)\n",
    "    plt.xticks(range(10, 211, 25), range(0, 2001, 250), fontsize=18)\n",
    "    plt.xlim(10, 160)\n",
    "    plt.yticks(range(0, 41, 10), fontsize=18)\n",
    "    plt.grid(b=False)\n",
    "    plt.savefig(\"%s/trust_vs_distrust/psd_wilcoxon_%s.png\" % (GROUP_RESULT_FOLDER, location.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = [['delta', 1, 4], ['theta', 4, 8], ['alpha', 8, 13], ['beta', 13, 30]]\n",
    "means_per_subject = np.zeros((len(SUBJECTS), len(bands), len(LOCATIONS), 2))\n",
    "time_from = 0.1\n",
    "time_to = 0.45\n",
    "for l, location in enumerate(LOCATIONS):\n",
    "    for b, band in enumerate(bands):\n",
    "        for s in range(len(SUBJECTS)):\n",
    "            subj_trust = np.median(powers_trust[s, np.array(eval(location))-1], axis=0)\n",
    "            means_per_subject[s, b, l, 1] = 100*np.median(np.sum(subj_trust[np.logical_and(freqs >= band[1], freqs <= band[2])], axis=0)[np.logical_and(times >= time_from, times <= time_to)]) / np.median(np.sum(subj_trust, axis=0)[np.logical_and(times >= time_from, times <= time_to)])\n",
    "            subj_distrust = np.median(powers_distrust[s, np.array(eval(location))-1], axis=0)\n",
    "            means_per_subject[s, b, l, 0] = 100*np.median(np.sum(subj_distrust[np.logical_and(freqs >= band[1], freqs <= band[2])], axis=0)[np.logical_and(times >= time_from, times <= time_to)]) / np.median(np.sum(subj_distrust, axis=0)[np.logical_and(times >= time_from, times <= time_to)])\n",
    "        p = pg.wilcoxon(means_per_subject[:, b, l, 0], means_per_subject[:, b, l, 1])['p-val'].values[0]\n",
    "        df = pd.DataFrame()\n",
    "        df[\"power\"] = means_per_subject[:, b, l].flatten()\n",
    "        df[\"condition\"] = [\"Distrust\", \"Trust\"]*len(SUBJECTS)\n",
    "        plt.figure(figsize=(2, 3))\n",
    "        sns.boxplot(data=df, x='condition', y='power', ax=plt.gca(), notch=False, width=0.9, linewidth=1.5,\n",
    "                    palette=[DISTRUST_COLOR, TRUST_COLOR])\n",
    "        sns.swarmplot(data=df, x='condition', y='power', ax=plt.gca(), color='0.2')\n",
    "        plt.xlabel(\"\")\n",
    "        if band[0] == \"alpha\":\n",
    "            plt.yticks([15, 25, 35], fontsize=18)\n",
    "            plt.ylim(15, 35)\n",
    "        elif band[0] == \"beta\":\n",
    "            plt.yticks([0, 25, 50], fontsize=18)\n",
    "            plt.ylim(0, 50)\n",
    "        elif band[0] == \"delta\":\n",
    "            plt.yticks([10, 35, 60], fontsize=18)\n",
    "            plt.ylim(10, 60)\n",
    "        elif band[0] == \"theta\":\n",
    "            plt.yticks([20, 35, 50], fontsize=18)\n",
    "            plt.ylim(20, 50)\n",
    "        plt.xticks([])\n",
    "        plt.ylabel(\"\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"%s/trust_vs_distrust/eeg_%s_%s.png\" % (GROUP_RESULT_FOLDER, band[0], location.lower()))\n",
    "        if p > 0.0125:\n",
    "            plt.clf()\n",
    "            plt.close()\n",
    "        else:\n",
    "            print(location, band)\n",
    "            print(pg.wilcoxon(means_per_subject[:, b, l, 0], means_per_subject[:, b, l, 1]))\n",
    "            print(pg.compute_effsize(means_per_subject[:, b, l, 0], means_per_subject[:, b, l, 1]))\n",
    "            plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('bari')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "a906a435e30dc427b173eaaf7f703355f379138123407c6300ba9ea1262ce443"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
